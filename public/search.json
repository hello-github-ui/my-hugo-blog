[{"categories":["笔记"],"content":"Redis主从复制 redis的主从复制概念和mysql的主从复制大概类似。一台主机master，一台从机slaver。master主机数据更新后根据配置和策略，自动同步到slaver从机，Master以写为主，Slaver以读为主。\n主要用途  读写分离：适用于读多写少的应用，增加多个从机，提高读的速度，提高程序的并发性 数据容灾恢复：从机复制主机的数据，相当于数据备份，如果主机数据丢失，那么可以通过从机存储的数据进行恢复 高并发、高可用集群实现的基础：在高并发的场景下，就算主机挂了，从机可以实现主从切换，从机自动成为主机对外提供服务  一主多从配置 环境准备 我们用一台机器模拟三个机器，\n将下载下来的redis复制三份\n1 2 3  cp -R redis-5.0.3 redis01 cp -R redis-5.0.3 redis02 cp -R redis-5.0.3 redis03   如下图所示：\n 然后，在一台机器上启动三个redis，一个作 master，两个作 slaver，\nmaster 端口：6380\nslaver1 端口：6381\nslaver2 端口：6382\n ","description":"","tags":["Redis","Centos"],"title":"Redis主从搭建","uri":"/redis%E4%B8%BB%E4%BB%8E%E6%90%AD%E5%BB%BA/"},{"categories":["编程"],"content":"AOP简介 来自于官方的定义：\n Aspect-oriented Programming (AOP) complements Object-oriented Programming (OOP) by providing another way of thinking about program structure. The key unit of modularity in OOP is the class, whereas in AOP the unit of modularity is the aspect. Aspects enable the modularization of concerns that cut across multiple types and objects.\n 面向切面编程，是spring框架中的一个重要内容。利用 aop 可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高代码的可重用性，提高开发效率。\nAOP一般用来实现以下几个功能：\n 日志记录，性能统计，安全控制，权限控制，事务处理，异常处理，资源池管理等\n 目前最受欢迎的aop库有两个，一个是 AspectJ，另一个是 Spring AOP。\n我们先来学习 Spring AOP，在学习之前，先学习几个 AOP 中的知识点：\n  Aspect：即切面，切面一般定义为一个java类，切面在 ApplicationContext 中的 \u003caop:aspect\u003e 来配置。\n  Joinpoint：即连接点，程序执行的某个点，比如方法执行。构造函数调用或者字段赋值等。在Spring AOP中，连接点只会有 方法调用（method execution）。\n  Advice：即通知，切面对于某个连接点所产生的动作，可以理解位：在连接点处要执行的代码，例如 TestAspect 对 com.spring.service 包下所有类的方法进行日志记录的动作就是一个Advice。其中一个切面可以包含多个Advice。Advice总共有如下5种类型：\n 1. 前置通知（Before advice）：在某个连接点（joinpoint）之前执行，xml中在\u003caop:aspect\u003e里面使用\u003caop:before\u003e元素进行声明；注解中使用@Before声明。\r2. 后置通知（After advice）：在某个连接点退出的时候执行，xml中在\u003caop:aspect\u003e里面使用\u003caop:after\u003e元素进行声明；注解中使用@After声明。\r3. 返回后通知（After return advice）：在某个连接点正常完成后执行的通知，不包括抛出异常的情况。xml中在\u003caop:aspect\u003e里面使用\u003cafter-returning\u003e元素进行声明。注解中使用@AfterReturning声明。\r4. 环绕通知（Around advice）：包围一个连接点的通知，可以在方法的调用前后完成自定义的行为，也可以选择不执行。xml中在\u003caop:aspect\u003e里面使用\u003caop:around\u003e元素进行声明；注解中使用@Around声明。\r5. 抛出异常后通知（After throwing advice）：在方法抛出异常退出时执行的通知。xml中在\u003caop:aspect\u003e里面使用\u003caop:after-throwing\u003e元素进行声明；注解中使用@AfterThrowing声明。\r   Pointcut：即切点，一个匹配连接点的正则表达式。当一个连接点匹配到切点时，一个关联到这个切点的特定的通知（Advice）会被执行。\n  Weaving：即编织，负责将切面和目标对象链接，以创建通知对象，在Spring AOP中没有这个东西\n  在spring框架中，aop有两种动态代理方式，其一是基于JDK的动态代理，需要代理的类实现某一个接口，其二是基于CGLIB 的方式，该方式不需要类实现接口就能进行代理。\n实操 接下来我们通过一个小demo来实操演练以下。\n创建项目 我们直接在 idea 中新建一个 spring initializr 工程，什么也不需要选择，创建一个空的即可。\n然后修改pom文件如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003cparent\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-parent\u003c/artifactId\u003e \u003cversion\u003e2.4.4\u003c/version\u003e \u003crelativePath/\u003e \u003c!-- lookup parent from repository --\u003e \u003c/parent\u003e \u003cgroupId\u003ecom.example\u003c/groupId\u003e \u003cartifactId\u003espring-aop-demo\u003c/artifactId\u003e \u003cversion\u003e0.0.1-SNAPSHOT\u003c/version\u003e \u003cname\u003espring-aop-demo\u003c/name\u003e \u003cdescription\u003eDemo project for Spring Boot\u003c/description\u003e \u003cproperties\u003e \u003cjava.version\u003e11\u003c/java.version\u003e \u003cproject.build.sourceEncoding\u003eUTF-8\u003c/project.build.sourceEncoding\u003e \u003cproject.reporting.outputEncoding\u003eUTF-8\u003c/project.reporting.outputEncoding\u003e \u003c/properties\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-aop\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-test\u003c/artifactId\u003e \u003cscope\u003etest\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003cbuild\u003e \u003cplugins\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-maven-plugin\u003c/artifactId\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003c/build\u003e \u003c/project\u003e   创建业务对象 业务对象就是一个普通的Java类，然后有自己的一些业务逻辑。我们就以下面这个微信服务对象为例，这个对象只有一个简单的业务逻辑就是：分享文章到朋友圈。\n在如下图所示位置创建对象：\n注意，上面使用到了 @Service 注解，表示将这个类注入到 spring ioc 中，成为spring容器中的一个 bean（只有这样后，才会在下面使用 getBean 获取到这个 bean 对象）\n在该类中定义如上的方法。\n然后在 SpringAopDemoApplication 启动类中增加如下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  package com.example.springaopdemo; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.context.ApplicationContext; @SpringBootApplication public class SpringAopDemoApplication { public static void main(String[] args) { ApplicationContext applicationContext = SpringApplication.run(SpringAopDemoApplication.class, args); WeixinService weixinService = applicationContext.getBean(WeixinService.class); weixinService.share(\"https://www.jianshu.com/u/db7d7a281529\"); } }   之后点击运行按钮，启动程序后在控制台可以看到如下输出：\n定义切面（Aspect） 上面我们创建了自己的业务对象，那么我们现在创建一个切面，使用 AOP 在不对业务进行修改的情况下增加一些额外的功能，比如在分享到朋友圈之后我们将这次分享记录到日志中。\n我们按照上面的方法在同样的包中创建类 WeixinServiceAspect\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  package com.example.springaopdemo; import org.aspectj.lang.JoinPoint; import org.aspectj.lang.annotation.AfterReturning; import org.aspectj.lang.annotation.Aspect; import org.springframework.stereotype.Component; /** * 定义 切面（Aspect） */ @Aspect @Component public class WeixinServiceAspect { // 使用返回后通知（Advice）  @AfterReturning(\"execution(public void WeixinService.share(String))\") public void log(JoinPoint joinPoint){ //JoinPoint连接点  System.out.println(joinPoint.getSignature() + \" executed\"); } }   同时在 SpringAopDemoApplication 中增加注解 @EnableAspectJAutoProxy\n那我们现在再来看一下程序的运行结果与上面比较有什么不一样呢？\n经过比较我们可以发现增加的日志记录已经在控制台输出了，但是很显然我们并没有修改我们原先的业务对象。\n到这里，大家应该对 aop 有了一个比较直观的感受了，下面我们就来具体说一说 Spring AOP 给我们提供了哪些 api 来使用。\nAPI Aspect 定义 在spring 中使用 Aspect 需要使用 @Component 直接将其标记为一个 Bean，\n并且使用 @Aspect 注解将其标记为一个切面\n然后在该类中定义上面我们所说的切点，通知等。\nPointCut 定义 这里我们说一下 pointcut 的表达式如何写，我们首先将上面例子中的切面类修改为如下：\n  使用 @Pointcut 注解的便是切点的定义\n  切点定义在方法上，并使用 @Pointcut 注解，注解中的值便是切点的表达式\n  切点的名称就是方法的名称，这里是 shareCut() ，注意这里有括号\n  若要将具体的通知 Advice 关联在某个切点上，只需要在 Advice 的注解上写上切点的名称就可以了，如下：\n1 2 3 4 5 6 7  // 使用返回后通知（Advice） // 连接点有多个，通过名称就将通知与某个切点关联起来了  @AfterReturning(\"shareCut()\") public void log(JoinPoint joinPoint){ //JoinPoint连接点  System.out.println(joinPoint.getSignature() + \" executed\"); }   \r  Pointcut 指示器 切点的表达式以指示器开始，指示器就是一种关键字，用来告诉 Spring AOP 如何匹配连接点，Spring AOP 提供了以下几种指示器\n e'x'ecution within this 和 target args @target @annotation  下面我们依次说明这些指示器的作用\nexecution\n该指示器用来匹配方法执行连接点，即匹配哪个方法执行，如\n1  @Pointcut(\"execution(public String com.example.springaopdemo.UserDao.findById(Long))\")   上面这个切点会匹配在UserDao类中findById方法的调用，并且需要该方法是public的，返回值类型为String，只有一个Long的参数。\n切点的表达式同时还支持宽字符匹配，如：\n1  @Pointcut(\"execution(* com.example.springaopdemo.UserDao.*(..))\")   上面的表达式中，第一个宽字符 * 匹配 任何返回类型，第二个宽字符 * 匹配 任何方法名，最后的参数 (..) 表达式匹配 任意数量任意类型 的参数，也就是说该切点会匹配类中所有方法的调用。\nwithin 如果要匹配一个类中所有方法的调用，便可以用 within 指示器\n1  @Pointcut(\"within(com.example.springaopdemo.UserDao)\")   这样便可以匹配该类中所有方法的调用了。同时我们还可以匹配某个包下面的所有类的所有方法调用，如下面的例子：\n1  @Pointcut(\"within(com.example.springaopdemo..*)\")   this和target\n如果目标对象实现了任何接口，Spring AOP会创建基于 CGLIB 的动态代理，这时候需要使用 target 指示器\n如果目标对象没有实现任何接口，Spring AOP 会创建基于 JDK 的动态代理，这时候需要使用 this 指示器\n1 2  @Pointcut(\"target(com.example.springaopdemo.A)\") A实现了某个接口 @Pointcut(\"this(com.example.springaopdemo.B)\") B没有实现任何一个接口   args 该指示器用来匹配具体的方法参数\n1  @Pointcut(\"execution(* *..find*(Long))\")   这个切点会匹配任何以 find 开头并且只有一个 Long 类型的参数的方法\n如果我们想匹配一个以 Long 类型开始的参数，后面的参数类型不做限制，我们可以使用如下的表达式：\n1  @Pointcut(\"execution(* *..find*(Long))\")   @target 该指示器不要和 target 指示器混淆，该指示器用于匹配连接点所在的类是否拥有指定类型的注解，如：\n1  @Pointcut(\"@target(org.springframework.stereotype.Repository)\")   @annotation 该指示器用于匹配连接点的方法是否具有某个注解\n1  @Pointcut(\"@annotation(org.springframework.scheduling.annotion.Async)\")   组合切点表达式 切点表达式可以通过 \u0026\u0026 、|| 和 ！等操作符来组合，如\n1 2 3 4 5 6 7 8  @Pointcut(\"@target(org.springframework.stereotype.Repository)\") public void repositoryMethods() {} @Pointcut(\"execution(* *..create*(Long,..))\") public void firstLongParamMethods() {} @Pointcut(\"repositoryMethods() \u0026\u0026 firstLongParamMethods()\") public void entityCreationMethods() {}   上面的第三个切点需要同时满足第一个和第二个切点表达式\nAdvice定义 Advice通知，即在连接点处要执行的代码，分为以下几种类型\n Around Before After  开启 Advice 如果要在Spring中使用Spring AOP，需要开启 Advice，使用 @EnableAspectJAutoProxy 注解就可以了，代码如下：\n1 2 3 4 5  @SpringBootApplication @EnableAspectJAutoProxy public class SpringAopDemoApplication{ }   自定义AOP Annotation 我们来了解一下如何使用aop以及aop的api，下面我们尝试自己定义一个aop的Annotation，@CalculateExecuteTime，任何使用该注解的方法，都会打印出该方法的执行时间\n创建 Annotation 1 2 3 4 5 6 7 8 9 10 11 12 13 14  package com.example.springaopdemo.myaop.annotation; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; /** * 任何使用该注解的方法，都会打印出该方法的执行时间 */ @Target(ElementType.METHOD) //该注解作用的对象 @Retention(RetentionPolicy.RUNTIME) //该注解使用的时机 public @interface CalculateExecuteTime { }   创建切面 1 2 3 4 5 6 7 8 9 10 11 12  package com.example.springaopdemo.myaop.aspect; import org.aspectj.lang.annotation.Aspect; import org.springframework.stereotype.Component; /** * 切面aspect */ @Aspect @Component public class CalculateExecuteTimeAspect { }   创建切点和通知 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  package com.example.springaopdemo.myaop.aspect; import com.example.springaopdemo.myaop.annotation.CalculateExecuteTime; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.Around; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Pointcut; import org.springframework.stereotype.Component; /** * 切面aspect */ @Aspect @Component public class CalculateExecuteTimeAspect { // 切点表达式，表示加了CalculateExecuteTime注解的都是切点，路径是自定义注解的全路径  @Pointcut(\"@annotation(com.example.springaopdemo.myaop.annotation.CalculateExecuteTime)\") public void pointcut(){ } @Around(\"@annotation(calculateExecuteTime)\") public Object logExecutionTime(ProceedingJoinPoint joinPoint, CalculateExecuteTime calculateExecuteTime) throws Throwable{ long start = System.currentTimeMillis(); Object proceed = joinPoint.proceed(); long executionTime = System.currentTimeMillis() - start; System.out.println(joinPoint.getSignature() + \" executed in \" + executionTime + \"ms\"); return proceed; } }   这里的 ProceedingJoinPoint 代表连接的方法\n在方法上加上自定义注解 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  package com.example.springaopdemo; import com.example.springaopdemo.myaop.annotation.CalculateExecuteTime; import org.springframework.stereotype.Service; import java.util.concurrent.TimeUnit; /** * 创建业务对象 * 业务对象就是一个普通的java类，然后有自己的一些业务逻辑。我们就以下面这个 \u003cstrong\u003e微信服务\u003c/strong\u003e * 对象为例，这个对象只有一个简单的业务逻辑就是 分享文章到朋友圈 */ @Service //注入到spring ioc 中的 bean public class WeixinService { @CalculateExecuteTime public void share(String articleUrl){ try { TimeUnit.SECONDS.sleep(3); }catch (Exception exception){ } } }   这里我们模拟该方法会执行3s的时间，运行程序以后得到如下结果：\n可以看到该 Advice 已经生效了。\n本文参考于: Spring AOP 教程 和 Spring AOP 自定义注解实现 \n","description":"","tags":["Spring AOP","Java","AOP"],"title":"Spring AOP学习（一）","uri":"/spring-aop%E5%AD%A6%E4%B9%A0%E4%B8%80/"},{"categories":["生活"],"content":"我来深圳了 2021年我来到了深圳，深圳的中心区（罗湖，福田，南山）消费是真的高的离谱，所以我呢选择了与别人合租，诺就是下图所示的房间环境，给你们看一下吧（位置还是挺好的，紧邻上沙地铁站，出了楼道门就是地铁站了）\n我住的呢就是刚进门你们看到挂衣服的那个床位，诶呀生活压力大啊。\n接下来呢 我打算好好努力干一段时间，攒点钱，之前自己实在是太任性了，也没挣到什么钱，真是羞愧呢，正如我今天看到敖丙离职的这篇文章说的那样，我们做不到逆风而起，但却可以选择向阳而生，加油吧！！！\n","description":"","tags":["心情"],"title":"深圳合租","uri":"/%E6%B7%B1%E5%9C%B3%E5%90%88%E7%A7%9F/"},{"categories":["编程"],"content":"sql mysql优化你是怎么做的？ 设计数据库时一定要考虑三大范式（确保每一列都保持原子性、确保表中的每一列都和主键相关、确保每一列都和主键列直接相关，而不是间接相关）\nmysql的行级锁，表级锁 行级锁是mysql中锁定粒度最细的一种锁，表示只对当前的行进行加锁。行级锁能大大减少数据库操作的冲突。行级锁分为 共享锁和排他锁\n特点：开销大，加锁慢，会出现死锁；锁定粒度最小，发生锁冲突的概率最小，并发度也最高\n表级锁是mysql中锁定粒度最大的一种锁，表示对当前操作的整张表加锁。最常使用的 MyISAM 与 InnoDB 都支持表级锁定。表级锁定分为 表共享读锁（共享锁）与 表独占写锁（排他锁）\n特点：开销小，加锁快，不会出现死锁；锁定粒度大，发生锁冲突的概率最大，并发度最低\n页级锁是mysql中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级锁冲突少，但速度慢。因此，采取了折中的页级锁，一次锁定相邻的一组记录。\n特点：开销和加锁时间介于表锁和行锁之间；会出现死锁；锁定粒度介于表锁和行锁之间，并发度一般\n 在 innodb 引擎中既支持行级锁也支持表级锁，那么什么时候会锁住整张表？什么时候只锁住一行呢？\ninnodb 行级锁是通过给索引上的 索引项 加锁来实现，这种特点意味着：在innodb中只有通过索引条件（不论是主键索引，非主键索引还是普通索引）检索数据时，innodb才会使用行级锁，否则innodb将使用表级锁\n 在mysql中，行级锁并不是直接锁定记录，而是锁定索引。索引分为主键索引和非主键索引两种。如果一条sql语句操作了主键索引，mysql就会锁定这条主键索引；如果一条sql语句操作了非主键索引，mysql就会先 锁定该 非主键索引，再锁定相关的主键索引；在进行update，delete操作时，mysql不仅锁定where条件扫描过的所有索引记录，而且会锁定相邻的键值，即所谓的next-key locking\n当两个事物同时执行，一个锁住了主键索引，在等待其它相关索引；另一个锁定了非主键索引，在等待主键索引。这样就会发生死锁。发生死锁后，innodb一般都可以检测到，并使一个事物释放锁回退，另一个获取锁完成事物。\nmysql避免死锁的方法 有多种方法可以避免死锁，这里只介绍常见的三种：\n 如果不同程序会并发存取多张表，尽量约定以相同的顺序访问表，可以大大降低发生死锁的可能性 在同一个事物中，尽可能做到一次锁定所需要的 所有资源，减少死锁产生概率 对于非常容易发生死锁的业务，可以尝试使用升级锁定颗粒度，比如通过表级锁来减少死锁产生的概率  内存溢出的解决方法 引起内存溢出的原因有多种，常见的有以下几种：\n 内存中加载的数据量过于庞大，如一次性从数据库中取出过多数据； 集合类中有对 对象的引用，使用完以后未清空，使得JVM不能自动回收； 代码中存在死循环或错误的递归或循环产生过多重复的对象实体（这一类属于代码层错误）； 项目中引入的第三方依赖有BUG； JVM启动参数内存值设定的过小。  解决方案\n第一步：修改JVM启动参数，直接增加内存空间（-Xms，-Xmx参数一定不要忘记加）。\n第二步：检查错误日志，查看 OutOfMemory 错误前是否有其它异常或错误。线上的话，可以使用Dump下来分析\n第三步：对代码进行分析，找出可能发生内存溢出的位置。\n第四步：使用内存查看工具动态查看内存使用情况。某个项目上线后，每次启动系统两天后，就会出现内存溢出的错误，这种情况一般都是代码中出现了缓慢的内存泄漏。这时就要用到内存查看工具了，比如 JProbe Profiler，Jconsole等\nsql慢查询处理方法 首先如何判别系统遇到了sql慢查询问题？从以下几个方面考虑：\n 数据库CPU负载过高，一般是查询语句中有很多计算逻辑，导致数据库cpu负载过高 IO负载高导致服务器卡住，这个一般和全表查询 没有索引 有关系 查询语句正常，索引正常但是确实慢。如果表的索引是正常的，但是查询慢，这时候需要看看是否 索引没有生效（explain一下）  如果出现了上述问题，解决办法：\n开启sql慢查询的日志，要开启日志，需要在mysql的配置文件my.cnf的 [mysqld] 项下配置慢查询日志开启，如下：\n1 2 3  [mysqld]slow_query_log=1 slow_query_log_file=/var/log/mysql/log-slow-queries.log long_query_time=2   索引失效的情况  如果查询条件中 or，即使其中有条件带索引也不会使用（这也是为什么尽量少用or的原因）  注意：要想使用or，又想要让索引生效，只能将or条件中的每个列都加上索引\n 对于多列索引，不是使用的第一部分（第一个），则不会使用索引（参考：你不知道的mysql多列索引的建立和优化） like 查询是以 % 开头的   如果列类型是字符串，那一定要在条件中将数据使用引号引用起来，否则不使用索引   如果mysql估计使用全表扫描要比使用索引快，则不使用索引  此外，查看索引的使用情况命令如下：\nshow status like 'Handler_read%'\n大家可以注意：\nhandler_read_key：这个值越高越好，越高表示使用索引查询到的次数越多\nhandler_read_rnd_next：这个值越高，说明查询低效\n参考链接\n为什么要分库分表  首先来说一下为什么要分库分表：数据库出现性能瓶颈，用大白话来说就是数据库快扛不住了。\n数据库出现性能瓶颈，对外表现有几个方面：\n 大量请求阻塞  在高并发场景下，大量请求都需要操作数据库，导致连接数不够了，请求处于阻塞状态。\n sql 操作变慢  如果数据库中存在一张上亿数据量的表，一条sql没有命中索引会全表扫描，这个查询耗时会非常久\n 存储出现问题  业务量剧增，单库数据量越来越大，给存储造成巨大压力\n sql 调优往往是解决数据库问题的第一步，往往投入少部分精力就能获得较大的收益。sql调优的主要目的是尽可能地让那些慢sql变快，手段其实也很简单就是让sql执行尽量命中索引。\n开启慢sql记录 如果你使用地是mysql，需要在mysql配置文件中配置几个参数即可。\n1 2 3  slow_query_log=on long_query_time=1 slow_query_log_file=/path/to/log   调优的工具 常常会用到explain这个命令来查看sql语句的执行计划，通过观察执行结果很容易就知道该sql语句是不是全表扫描，有没有命中索引\n1  EXPLAIN SELECT * FROM cnarea_2019 where `name` = '肥东路社区居委会';   可以看到返回有有一列叫“type”，常见取值有：ALL、index、range、 ref、eq_ref、const、system、NULL（从左到右，性能从差到好）\nALL代表这条sql语句全表扫描了，需要优化。一般来说需要达到range级别及以上\n表结构优化  以一个场景举例说明：\n  “user”表中有 user_id、nickname 等字段，“order”表中有order_id、user_id等字段，如果想拿到用户昵称怎么办？一般情况是通过 join 关联表操作，在查询订单表时关联查询用户表，从而获取导用户昵称。\n  但是随着业务量的增加，订单表和用户表肯定也是暴增，这时候通过两个表关联数据就比较费力了，为了取一个昵称字段而不得不关联查询几十上百万的用户表，其速度可想而知！\n  这个时候可以尝试将nickname这个字段加到order表中（order_id、user_id、nickname），这种做法通常叫做数据库表冗余字段。这样做的好处是展示订单列表时不需要再关联查询用户表了\n  冗余字段的做法也有一个弊端，如果这个字段更新会同时涉及到多个表的更新，因此在选择冗余字段时要尽量选择不经常更新的字段。\n 架构优化 当单台数据库实例扛不住，我们可以增加实例组成集群对外服务\n当发现读请求明显多于写请求时，我们可以让 主实例负责写，从实例 对外提供读的能力\n如果读实例压力依然很大，可以在数据库前面加入缓存如redis，让请求优先从缓存取数据减少数据库访问\n缓存分担了部分压力后，数据库依然是瓶颈时，这个时候就可以考虑分库分表的方案了。后面会详细介绍\n硬件优化 硬件成本非常高，一般来说不可能遇到数据库性能瓶颈问题就去升级硬件\n在前期业务量比较小的时候，升级硬件数据库性能可以得到比较大的提升，但是在后期，升级硬件得到的性能提升就不那么明显了\n分库分表详解 分库 下面我们以一个商城系统为例逐步说明数据库是如何一步一步演进\n单应用数据库\n在早期创业阶段想做一个商城系统，基本就是一个系统包含多个基础功能模块，最后打包成一个war包部署，这就是典型的单体架构应用。\n如上图，商城系统包括主页Portal模块，用户模块，订单模块，库存模块等，所有的模块都共有一个数据库，通常数据库中有非常多的表。\n因为用户量不大，这样的架构在早期完全适用。\n多应用但数据库\n在前期为了抢占市场，这一套系统就不停的迭代更新，代码量越来越大，架构也变得越来越臃肿，现在随着系统访问压力逐渐增加，系统拆分就势在必行了。\n为了保证业务平滑，系统架构的重构也是分了几个阶段进行。\n第一个阶段将商城系统单体架构按照功能模块拆分为子服务，比如：Portal服务、用户服务、订单服务、库存服务等。\n如上图，多个服务共享一个数据库，这样做的目的是底层数据库访问逻辑可以不用动，将影响降到最低。\n多应用多数据库\n随着业务推广力度加大，数据库终于成为了瓶颈，这个时候多个服务共享一个数据库基本不可行了。我们需要将每个服务相关的表拆分出来单独建立一个数据库，这其实就是“分库”了。\n单数据库能够支撑的并发量是有限的，拆分成多个库可以使服务间不用竞争，提升服务的性能。\n如上图，从一个大的数据库中分出多个小的数据库，每个服务都对应一个数据库，这就是系统发展到一定阶段必须要做的“分库”操作\n现在非常火的微服务架构也是一样的，如果只拆分应用不拆分数据库，不能解决根本问题，整个系统也很容易达到瓶颈。\n分表 说完了分库，那什么时候分表呢？\n如果系统处于高速发展阶段，拿商城系统来说，一天下单量可能几十万，那数据库中的订单表增长就特别快，增长到一定阶段数据库查询效率就会出现明显下降。\n因此，当单表数据增量过快，业界流传是超过500万的数据量就要考虑分表了。当然500万只是一个经验值，具体根据实际情况来做出决策。\n那如何分表呢？\n分表有几个维度，一是*水平切分和垂直切分*，二是*单库内分表和多库内分表*\n水平拆分和垂直拆分\n就拿用户表（user）来说，表中有7个字段：id,name,age,sex,nickname,description，如果nickname和description不常用，我们可以将其拆分为另外一张表：用户详细信息表，这样就由一张用户表拆分为了用户基本信息表+用户详细信息表，两张表结构不一样相互独立。但是从这个角度来看垂直拆分并没有从根本上解决单表数据量过大的问题，因此我们还需要做一次水平拆分。\n还有一种拆分方法，比如表中有一万条数据，我们拆分为两张表，id为奇数的：1，3，5，7.。。。放在user1表中，id为偶数的：2，4，6，8.。。。放在user2中，这样的拆分办法就是水平拆分了。\n水平拆分的方式很多，除了上面说的按照id拆表，还可以按照时间维度去拆分，比如订单表，可以按照每日，每月等进行拆分。\n 每日表：只存储当天的数据 每月表：可以起一个定时任务将前一天的数据全部迁移到当月表 历史表：同样可以用定时任务把时间超过30天的数据迁移到 history 表  总结一下水平拆分和垂直拆分的特点：\n 垂直拆分：基于表或字段拆分，表结构不同 水平拆分：基于数据拆分，表结构相同，数据不同。  单库内拆分和多库内拆分\n拿水平拆分为例，每张表都拆分为了多个子表，多个子表存在于同一数据库中。比如下面用户表拆分为用户表1和用户表2.\n在一个数据库中将一张表拆分为几个子表在一定程度上可以解决单表查询性能的问题，但是也会遇到一个问题：单数据库存储瓶颈。\n所以在业界用的更多的还是将子表拆分到多个数据库中。比如下图中，用户表拆分为两个子表，两个子表分别存在于不同的数据库中。\n一句话总结：分表主要是为了减少单张表的大小，解决单表数据量带来的性能问题。\n分库分表带来的复杂性 既然分库分表这么好，那我们是不是在项目初期就应该采用这种方案呢？不要激动，冷静一下，分库分表的确解决了很多问题，但是也给系统带来了很多复杂性，下面简要地谈一谈。\n（1）跨库关联查询\n在单库未拆分表之前，我们可以很方便的使用 join 操作关联多张表查询数据，但是经过分库分表之后两张表可能都不在一个数据库中，如何使用 join 呢？\n有几种方案可以解决：\n 字段冗余：把需要关联的字段放入主表中，避免join操作； 数据抽象：通过 ETL 等将数据汇合聚集，生成新的表； 全局表：比如一些基础表可以在每个数据库中都放一份； 应用层组装：将基础数据查出来，通过应用程序计算组装。  （2）分布式事物\n单数据库可以用本地事务搞定，使用多数据库就只能通过分布式事物解决了。\n常用的解决方案有：基于可靠消息（MQ）的解决方案、两阶段事物提交、柔性事物等。\n（3）排序、分页、函数计算问题\n在使用sql的 order by，limit等关键字需要特殊处理，一般来说采用分片的思路：\n先在每个分片上执行相应的函数，然后将各个分片的结果集进行汇总和再次计算，最终得到结果。\n（4）分布式ID\n如果使用mysql数据库在单库单表里面可以使用id自增作为主键，分库分表了之后就不行了，会出现id重复。\n常用的分布式ID解决方案有：\n uuid 基于数据库自增单独维护一张 ID 表 号段模式 Redis缓存 雪花算法（SnowFlake） 百度 uid-generator 美团 Leaf 滴滴 Tinyid  （5）多数据源\n分库分表之后可能会面临从 多个数据库或多个子表中获取数据，一般的解决思路有：客户端适配和代理层适配。\n业界常用的中间件有：\n shardingsphere（前身 sharding-jdbc） Mycat  Redis Redis 的淘汰策略 将redis作为缓存使用时，当redis内存超出物理内存限制时，内存数据就会与磁盘产生频繁交换，导致redis性能急剧下降。此时如何淘汰无用数据释放空间，就很重要了。\nredis在生产环境中，采用配置参数 maxmemory 的方式来限制内存大小，当实际内存超出这个值时，通过以下几种方式淘汰：\n volatile-lru：从设置过期时间的数据集(server.db[i].expires)中挑选出最近最少使用的数据淘汰。没有设置过期时间的key不会被淘汰，这样就可以在增加内存空间的同时保证需要持久化的数据不会丢失。 volatile-ttl：除了淘汰机制采用LRU，策略基本上与volatile-lru相似，从设置过期时间的数据集(server.db[i].expires)中挑选将要过期的数据淘汰，ttl值越大越优先被淘汰。 volatile-random：从已设置过期时间的数据集(server.db[i].expires)中任意选择数据淘汰。当内存达到限制无法写入非过期时间的数据集时，可以通过该淘汰策略在主键空间中随机移除某个key。 allkeys-lru：从数据集(server.db[i].dict)中挑选最近最少使用的数据淘汰，该策略要淘汰的key面向的是全体key集合，而非过期的key集合。 allkeys-random：从数据集(server.db[i].dict)中选择任意数据淘汰。 no-enviction：禁止驱逐数据，也就是当内存不足以容纳新入数据时，新写入操作就会报错，请求可以继续进行，线上任务也不能持续进行，采用no-enviction策略可以保证数据不被丢失，这也是系统默认的一种淘汰策略。  上述是Redis的6种淘汰策略，关于使用这6种策略，开发者还需要根据自身系统特征，正确选择或修改驱逐。\n 在Redis中，数据有一部分访问频率较高，其余部分访问频率较低，或者无法预测数据的使用频率时，设置allkeys-lru是比较合适的。 如果所有数据访问概率大致相等时，可以选择allkeys-random。 如果研发者需要通过设置不同的ttl来判断数据过期的先后顺序，此时可以选择volatile-ttl策略。 如果希望一些数据能长期被保存，而一些数据可以被淘汰掉时，选择volatile-lru或volatile-random都是比较不错的。 由于设置expire会消耗额外的内存，如果计划避免Redis内存在此项上的浪费，可以选用allkeys-lru 策略，这样就可以不再设置过期时间，高效利用内存了。  如何保证缓存数据一致 只要使用到缓存，无论是本地内存做缓存还是使用 redis 做缓存，那么就会存在数据同步的问题，因为配置信息缓存在内存中，而内存时无法感知到数据在数据库的修改。这样就会造成数据库中的数据与缓存中数据不一致的问题。接下来就讨论一下关于保证缓存和数据库双写时的数据一致性。\n解决方案\n那么我们这里列出来所有策略，并且讨论他们优劣性。\n 先更新数据库，后更新缓存 先更新数据库，后删除缓存 先更新缓存，后更新数据库 先删除缓存，后更新数据库（个人建议这种，利用延时删除的策略）  先更新数据库，后删除缓存\n此时解决方案就是利用消息队列进行删除的补偿。具体的业务逻辑用语言描述如下：\n 请求 A 先对数据库进行更新操作 在对 Redis 进行删除操作的时候发现报错，删除失败 此时将Redis 的 key 作为消息体发送到消息队列中 系统接收到消息队列发送的消息后再次对 Redis 进行删除操作  但是这个方案会有一个缺点就是会对业务代码造成大量的侵入，深深的耦合在一起，所以这时会有一个优化的方案，我们知道对 Mysql 数据库更新操作后再 binlog 日志中我们都能够找到相应的操作，那么我们可以订阅 Mysql 数据库的 binlog 日志对缓存进行操作。\n参考链接\nZookeeper Zookeeper是一个开源的分布式协调服务，它的目标是可以提供高性能、高可用和顺序访问控制的能力，同时也是为了解决分布式环境下数据一致性的问题。\n集群 首先，Zookeeper集群中有几个关键的概念，Leader、Follower和Observer，Zookeeper中通常只有Leader节点可以写入，Follower和Observer都只是负责读，但是Follower会参与节点的选举和过半写成功，Observer则不会，它只是单纯的提供读取数据的功能。\n通常这样设置的话，是为了避免太多的节点参与过半写的过程，导致影响性能，这样Zookeeper只要使用一个几台机器的小集群就可以实现高性能了，如果要横向扩展的话，只需要增加Observer节点即可。\nZookeeper建议集群节点个数为奇数，只要超过一般的机器能够正常提供服务，那么整个集群都是可用的状态。\n数据节点Znode Zookeeper中数据存储于内存之中，这个数据节点就叫做Znode，它是一个树形结构，比如/a/b/c类似。\n而Znode又分为持久节点、临时节点、顺序节点三大类。\n持久节点是指只要被创建，除非主动移除，否则都应该一直保持在Zookeeper中。\n临时节点不同的是，它的声明周期和客户端Session会话一样，会话失效，那么临时节点就会被移除。\n还有就是临时顺序节点和持久顺序节点，除了基本的特性之外，子节点的名称还是有有序性。\n会话Session 会话自然就是指Zookeeper客户端和服务端之间的通信，它们使用TCP长连接的方式保持通信，通常，肯定会有心跳检测的机制，同时它可以接受来自服务器的watch事件通知。\n事件监听器Watcher 用户可以在指定的节点上注册watcher，这样在事件触发的时候，客户端就会收到来自服务端的通知。\n权限控制 ACL Zookeeper使用 acl 来进行权限的控制，包含以下五种：\n create，创建子节点权限 delete，删除子节点权限 read，获取节点数据和子节点列表权限 write，更新节点权限 admin，设置节点 ACL 权限  所以，Zookeeper通过集群的方式来做到高可用，通过内存数据节点Znode来达到高性能，但是存储的数据量不能太大，通常使用于读多写少的场景。\nZookeeper有哪些应用场景  命名服务Name Service，依赖Zookeeper可以生成全局唯一的节点id，来对分布式系统中的资源进行管理。 分布式协调，这是Zookeeper的核使用了。利用watcher的监听机制，一个系统的某个节点状态发生改变，另外系统可以得到通知。 集群管理，分布式集群中状态的监控和管理，使用Zookeeper来存储。 Master选举，利用Zookeeper节点的全局唯一性，同时只有一个客户端能够创建成功的特点，可以作为Master选举使用，创建成功的则作为Master。 分布式锁，利用Zookeeper创建临时顺序节点的特性。  说说watcher监听机制和它的原理？ Zookeeper可以提供分布式数据的发布/订阅功能，依赖的就是watcher监听机制。\n客户端可以向服务端注册watcher监听，服务端的指定事件触发之后，就会向客户端发送一个事件通知。\n它有几个特性：\n 一次性，一旦一个watcher触发之后，Zookeeper就会将它从存储中移除。 客户端串行，客户端的watcher回调处理是串行同步的过程，不要因为一个watcher的逻辑阻塞整个客户端。 轻量，watcher通知的单位是watchedEvent，只包含通知状态、事件类型和节点类型，不包含具体的事件内容，具体的事件内容需要客户端主动去重新获取数据。  主要流程如下：\n 客户端向服务端注册watcher监听 保存watcher对象到客户端本地的watcherManager中 服务端watcher事件触发后，客户端收到服务端通知，从watcherManager中取出对应的watcher对象执行回调逻辑。  Zookeeper是如何保证数据一致性的 Zookeeper通过ZAB原子广播协议来实现数据的最终顺序一致性，他是一个类似2PC两阶段提交的过程。\n由于Zookeeper只有Leader节点可以写入数据，如果是其他节点收到写入数据的请求，则会将之转发给Leader节点。\n主要流程如下：\n Leader收到请求之后，将它转换为一个proposal提议，并且为每个提议分配一个全局唯一递增的事务ID：zxid，然后把提议放入到一个FIFO的队列中，按照FIFO的策略发送给所有的Follower Follower收到提议之后，以事务日志的形式写入到本地磁盘中，写入成功后返回ACK给Leader Leader在收到超过半数的Follower的ACK之后，即可认为数据写入成功，就会发送commit命令给Follower告诉他们可以提交proposal了  ZAB包含两种基本模式，崩溃恢复和消息广播。\n整个集群服务在启动、网络中断或者重启等异常情况的时候，首先会进入到崩溃恢复状态，此时会通过选举产生Leader节点，当集群过半的节点都和Leader状态同步之后，ZAB就会退出恢复模式。之后，就会进入消息广播的模式。\nZookeeper如何进行Leader选举的？ Leader的选举可以分为两个方面，同时选举主要包含事务zxid和myid，节点主要包含LEADING\\FOLLOWING\\LOOKING3个状态。\n 服务启动期间的选举 服务运行期间的选举  服务启动期间的选举\n 首先，每个节点都会对自己进行投票，然后把投票信息广播给集群中的其他节点 节点接收到其他节点的投票信息，然后和自己的投票进行比较，首先zxid较大的优先，如果zxid相同那么则会去选择myid更大者，此时大家都是LOOKING的状态 投票完成之后，开始统计投票信息，如果集群中过半的机器都选择了某个节点机器作为leader，那么选举结束 最后，更新各个节点的状态，leader改为LEADING状态，follower改为FOLLOWING状态  服务运行期间的选举\n如果开始选举出来的leader节点宕机了，那么运行期间就会重新进行leader的选举。\n leader宕机之后，非observer节点都会把自己的状态修改为LOOKING状态，然后重新进入选举流程 生成投票信息(myid,zxid)，同样，第一轮的投票大家都会把票投给自己，然后把投票信息广播出去 接下来的流程和上面的选举是一样的，都会优先以zxid，然后选择myid，最后统计投票信息，修改节点状态，选举结束  那选举之后又是怎样进行数据同步的？ 那实际上Zookeeper在选举之后，Follower和Observer（统称为Learner）就会去向Leader注册，然后就会开始数据同步的过程。\n数据同步包含3个主要值和4种形式。\nPeerLastZxid：Learner服务器最后处理的ZXID\nminCommittedLog：Leader提议缓存队列中最小ZXID\nmaxCommittedLog：Leader提议缓存队列中最大ZXID\n直接差异化同步 DIFF同步\n如果PeerLastZxid在minCommittedLog和maxCommittedLog之间，那么则说明Learner服务器还没有完全同步最新的数据。\n 首先Leader向Learner发送DIFF指令，代表开始差异化同步，然后把差异数据（从PeerLastZxid到maxCommittedLog之间的数据）提议proposal发送给Learner 发送完成之后发送一个NEWLEADER命令给Learner，同时Learner返回ACK表示已经完成了同步 接着等待集群中过半的Learner响应了ACK之后，就发送一个UPTODATE命令，Learner返回ACK，同步流程结束  先回滚再差异化同步 TRUNC+DIFF同步\n这个设置针对的是一个异常的场景。\n如果Leader刚生成一个proposal，还没有来得及发送出去，此时Leader宕机，重新选举之后作为Follower，但是新的Leader没有这个proposal数据。\n举个栗子：\n假设现在的Leader是A，minCommittedLog=1，maxCommittedLog=3，刚好生成的一个proposal的ZXID=4，然后挂了。\n重新选举出来的Leader是B，B之后又处理了2个提议，然后minCommittedLog=1，maxCommittedLog=5。\n这时候A的PeerLastZxid=4，在(1,5)之间。\n那么这一条只存在于A的提议怎么处理？\nA要进行事务回滚，相当于抛弃这条数据，并且回滚到最接近于PeerLastZxid的事务，对于A来说，也就是PeerLastZxid=3。\n流程和DIFF一致，只是会先发送一个TRUNC命令，然后再执行差异化DIFF同步。\n仅回滚同步 TRUNC同步\n针对PeerLastZxid大于maxCommittedLog的场景，流程和上述一致，事务将会被回滚到maxCommittedLog的记录。\n这个其实就更简单了，也就是你可以认为TRUNC+DIFF中的例子，新的Leader B没有处理提议，所以B中minCommittedLog=1，maxCommittedLog=3。\n所以A的PeerLastZxid=4就会大于maxCommittedLog了，也就是A只需要回滚就行了，不需要执行差异化同步DIFF了。\n全量同步 SNAP同步\n适用于两个场景：\n PeerLastZxid小于minCommittedLog Leader服务器上没有提议缓存队列，并且PeerLastZxid不等于Leader的最大ZXID  这两种场景下，Leader将会发送SNAP命令，把全量的数据都发送给Learner进行同步。\n有可能会出现数据不一致的问题吗？ 还是会存在的，我们可以分成3个场景来描述这个问题。\n查询不一致\n因为Zookeeper是过半成功即代表成功，假设我们有5个节点，如果123节点写入成功，如果这时候请求访问到4或者5节点，那么有可能读取不到数据，因为可能数据还没有同步到4、5节点中，也可以认为这算是数据不一致的问题。\n解决方案可以在读取前使用sync命令。\nleader未发送proposal宕机\n这也就是数据同步说过的问题。\nleader刚生成一个proposal，还没有来得及发送出去，此时leader宕机，重新选举之后作为follower，但是新的leader没有这个proposal。\n这种场景下的日志将会被丢弃。\nleader发送proposal成功，发送commit前宕机\n如果发送proposal成功了，但是在将要发送commit命令前宕机了，如果重新进行选举，还是会选择zxid最大的节点作为leader，因此，这个日志并不会被丢弃，会在选举出leader之后重新同步到其他节点当中。\n如果作为注册中心，Zookeeper 和Eureka、Consul、Nacos有什么区别？     Nacos Eureka Consul Zookeeper     一致性协议 CP+AP AP CP CP   健康检查 TCP/HTTP/MYSQL/Client Beat Client Beat TCP/HTTP/gRPC/Cmd Keep Alive   负载均衡策略 权重/ metadata/Selector Ribbon Fabio —   雪崩保护 有 有 无 无   自动注销实例 支持 支持 不支持 支持   访问协议 HTTP/DNS HTTP HTTP/DNS TCP   监听支持 支持 支持 支持 支持   多数据中心 支持 支持 支持 不支持   跨注册中心同步 支持 不支持 支持 不支持   SpringCloud集成 支持 支持 支持 不支持   Dubbo集成 支持 不支持 不支持 支持   K8S集成 支持 不支持 支持 不支持    最后，你对于CAP理论怎么理解？ CAP是一个分布式系统设计的定理，他包含3个部分，并且最多只能同时满足其中两个。\n Consistency一致性，因为在一个分布式系统中，数据肯定需要在不同的节点之间进行同步，就比如Zookeeper，所以一致性就是指的是数据在不同的节点之间怎样保证一致性，对于纯理论的C而言，默认的规则是忽略掉延迟的，因为如果考虑延迟的话，因为数据同步的过程无论如何都会有延迟的，延迟的过程必然会带来数据的不一致。 Availability可用性，这个指的是对于每一个请求，节点总是可以在合理的时间返回合理的响应，比如Zookeeper在进行数据同步时，无法对外提供读写服务，不满足可用性要求。这里常有的一个例子是说Zookeeper选举期间无法提供服务不满足A，这个说法并不准确，因为CAP关注的是数据的读写，选举可以认为不在考虑范围之内。所以，可以认为对于数据的读写，无论响应超时还是返回异常都可以认为是不满足A。 Partition-tolerance分区容错性，因为在一个分布式系统当中，很有可能由于部分节点的网络问题导致整个集群之间的网络不连通，所以就产生了网络分区，整个集群的环境被分隔成不同的的子网，所以，一般说网络不可能100%的不产生问题，所以P一定会存在。  为什么只能同时满足CAP中的两个呢？\n以A\\B两个节点同步数据举例，由于P的存在，那么可能AB同步数据出现问题。\n如果选择AP，由于A的数据未能正确同步到B，所以AB数据不一致，无法满足C。\n如果选择CP，那么B就不能提供服务，就无法满足A。\n","description":"","tags":["Java","面试"],"title":"Java知识点（一）","uri":"/java%E7%9F%A5%E8%AF%86%E7%82%B9%E4%B8%80/"},{"categories":["编程"],"content":" 首先我们来看Python版本的实现：\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  #!/usr/bin/env python # -*- coding: utf-8 -*- # @Time 2021/3/13 10:21 # @Author latin-xiao-mao # @Version v1.0 # @File BatchRename.py import os import random class BatchRename(): def __init__(self): self.path = 'E:/github-project/18x-images/' # 表示需要命名处理的文件夹 print(self.path) def rename(self): files = os.listdir(self.path) # 获取文件路径 random.shuffle(files) print(files) total_num = len(files) # 获取文件长度（个数） # new_filepath='/home/tanBin/deepLearning/python_learning/caiLearning/crawl_picture/tmp/' # if not os.path.exists(new_filepath): # os.makedirs(new_filepath) i = 202101 # 图片开始重命名的名称 for item in files: # print item if item.endswith('.jpg') or item.endswith('.webp') or item.endswith('.png'): # 源文件是png格式及其他格式 src = os.path.join(os.path.abspath(self.path), item) dst = os.path.join(os.path.abspath(self.path), format(str(i), '0\u003e6s') + '.jpg') # 处理后的格式也为jpg格式的 os.rename(src, dst) print('converting %sto %s...' % (src, dst)) i = i + 1 print('total %dto rename \u0026 converted %djpgs' % (total_num, i)) if __name__ == '__main__': newName = BatchRename() newName.rename()    首先我们来看Java版本的实现：\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  package tool; import java.io.File; import java.text.SimpleDateFormat; import java.util.Date; /** * 批量修改图片名字 */ public class BatchRename { public static void main(String[] args) { BatchRename.rename(); } public static void rename() { //输入的目录路径  String _path = \"E:\\\\photos\\\\网图\"; //将要实现的转换格式  String targetSuffix = \".png\"; //目标文件夹路径  File file = new File(_path); //如果目录存在  if (file.exists() \u0026\u0026 file.isDirectory()) { //获取目标目录下所有的文件数组  File[] files = file.listFiles(); //标记该数组的长度  int len = files.length; System.out.println(file + \"目录下总共有：\" + len + \"个文件\"); for (int i = 0; i \u003c len; i++) { String name = files[i].getName(); int index = name.lastIndexOf(\".\"); //获取后缀名  String suffixName = name.substring(index); //通过后缀名判断图片  if (\".jpg\".equals(suffixName) || \".png\".equals(suffixName) || \".webp\".equals(suffixName)){ String newName = new SimpleDateFormat(\"yyyyMMddhhmmss\").format(new Date()) + (i + 1) + targetSuffix; //重命名  File dest = new File(_path + \"/\" + newName); files[i].renameTo(dest); System.out.println(_path + \"\\\\\" + name + \" 重命名为：\" + dest.getName() + \"成功\"); }else System.out.println(_path + \"\\\\\" + name + \" 文件不是一个图片文件\"); } } } }   ","description":"","tags":["Python","Java"],"title":"代码实现批量重命名图片","uri":"/%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E6%89%B9%E9%87%8F%E9%87%8D%E5%91%BD%E5%90%8D%E5%9B%BE%E7%89%87/"},{"categories":["生活"],"content":"\r","description":"","tags":["网图"],"title":"网图集","uri":"/%E7%BD%91%E5%9B%BE%E9%9B%86/"},{"categories":["编程"],"content":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259  \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003cmeta charset=\"utf-8\"\u003e \u003cmeta name=\"viewport\" content=\"width=device-width,initial-scale=1.0\"\u003e \u003ctitle\u003e立体相册\u003c/title\u003e \u003cstyle type=\"text/css\"\u003e * { margin: 0px; padding: 0px; } html, body { height: 100%; width: 100%; background-color: silver; } .my-container { width: 100%; height: 200px; margin: 0px auto; margin-top: 200px; /*border-radius: 20px;*/ /*background-color: firebrick;*/ } .my-container .photo { /*border-radius: 20px;*/ height: 100%; width: 100%; perspective: 1200px; perspective-origin: 613px -800px; animation: shijiao 3s linear infinite alternate 4s; } @keyframes shijiao { from { perspective: 1200px; perspective-origin: 613px -800px; } to { perspective: 1200px; perspective-origin: 613px 300px; } } .my-container .photo .container { height: 100%; width: 100px; transform-style: preserve-3d; position: relative; margin: 0px auto; /*border-radius: 20px;*/ animation: xuanzhuan 5s linear 4s infinite; } @keyframes xuanzhuan { from { transform: rotateY(0deg); } to { transform: rotateY(-360deg); } } .my-container .photo .container .img { height: 200px; width: 100px; /*background-color: darkgoldenrod;*/ position: absolute; border-radius: 20px; background-color: transparent; /*border: 3px solid white;*/ box-shadow: 0px 0px 10px rgba(0, 0, 0, .3); } img { height: 180px; width: 90px; display: block; margin: 10px 5px; } .img1 { /*background-color: red;*/ transform: translateZ(0px); animation: zhuan1 4s linear forwards; } @keyframes zhuan1 { 14.28% { transform: translateX(-212.1px) translateZ(212.1px) rotateY(-45deg); } 28.56% { transform: translateX(-300px) translateZ(0px) rotateY(-90deg); } 42.84% { transform: translateX(-212.1px) translateZ(-212.1px) rotateY(-135deg); } 57.12% { transform: translateX(0px) translateZ(-300px) rotateY(-180deg); } 71.40% { transform: translateX(212.1px) translateZ(-212.1px) rotateY(-225deg); } 85.68% { transform: translateX(300px) translateZ(0px) rotateY(-270deg); } 100% { transform: translateX(212.1px) translateZ(212.1px) rotateY(-315deg); } } .img2 { /*background-color: black;*/ transform: translateZ(-10px); animation: zhuan2 3.5s linear .5s forwards; } @keyframes zhuan2 { 16.6% { transform: translateX(-212.1px) translateZ(212.1px) rotateY(-45deg); } 33.2% { transform: translateX(-300px) translateZ(0px) rotateY(-90deg); } 49.8% { transform: translateX(-212.1px) translateZ(-212.1px) rotateY(-135deg); } 66.4% { transform: translateX(0px) translateZ(-300px) rotateY(-180deg); } 83% { transform: translateX(212.1px) translateZ(-212.1px) rotateY(-225deg); } 100% { transform: translateX(300px) translateZ(0px) rotateY(-270deg); } } .img3 { /*background-color: khaki;*/ transform: translateZ(-20px); animation: zhuan3 3s linear 1s forwards; } @keyframes zhuan3 { 20% { transform: translateX(-212.1px) translateZ(212.1px) rotateY(-45deg); } 40% { transform: translateX(-300px) translateZ(0px) rotateY(-90deg); } 60% { transform: translateX(-212.1px) translateZ(-212.1px) rotateY(-135deg); } 80% { transform: translateX(0px) translateZ(-300px) rotateY(-180deg); } 100% { transform: translateX(212.1px) translateZ(-212.1px) rotateY(-225deg); } } .img4 { /*background-color: violet;*/ transform: translateZ(-30px); animation: zhuan4 2.5s linear 1.5s forwards; } @keyframes zhuan4 { 25% { transform: translateX(-212.1px) translateZ(212.1px) rotateY(-45deg); } 50% { transform: translateX(-300px) translateZ(0px) rotateY(-90deg); } 75% { transform: translateX(-212.1px) translateZ(-212.1px) rotateY(-135deg); } 100% { transform: translateX(0px) translateZ(-300px) rotateY(-180deg); } } .img5 { /*background-color: aqua;*/ transform: translateZ(-40px); animation: zhuan5 2s linear 2s forwards; } @keyframes zhuan5 { 33.3% { transform: translateX(-212.1px) translateZ(212.1px) rotateY(-45deg); } 66.6% { transform: translateX(-300px) translateZ(0px) rotateY(-90deg); } 100% { transform: translateX(-212.1px) translateZ(-212.1px) rotateY(-135deg); } } .img6 { /*background-color: saddlebrown;*/ transform: translateZ(-50px); animation: zhuan6 1.5s linear 2.5s forwards; } @keyframes zhuan6 { 50% { transform: translateX(-212.1px) translateZ(212.1px) rotateY(-45deg); } 100% { transform: translateX(-300px) translateZ(0px) rotateY(-90deg); } } .img7 { /*background-color: darkblue;*/ transform: translateZ(-60px); animation: zhuan7 1s linear 3s forwards; } @keyframes zhuan7 { 100% { transform: translateX(-212.1px) translateZ(212.1px) rotateY(-45deg); } } .img8 { /*background-color: hotpink;*/ transform: translateZ(-70px); animation: zhuan8 .5s linear 3.5s forwards; } @keyframes zhuan8 { 100% { transform: translateZ(300px); } } \u003c/style\u003e \u003c/head\u003e \u003cbody\u003e \u003cdiv class=\"my-container\"\u003e \u003cdiv class=\"photo\"\u003e \u003cdiv class=\"container\"\u003e \u003cdiv class=\"img img1\"\u003e \u003cimg src=\"https://img.imgdb.cn/item/604b887f5aedab222cebfe8e.jpg\"/\u003e \u003c/div\u003e \u003cdiv class=\"img img2\"\u003e \u003cimg src=\"https://img.imgdb.cn/item/604b887f5aedab222cebfe88.jpg\"/\u003e \u003c/div\u003e \u003cdiv class=\"img img3\"\u003e \u003cimg src=\"https://img.imgdb.cn/item/604b88715aedab222cebf619.jpg\"/\u003e \u003c/div\u003e \u003cdiv class=\"img img4\"\u003e \u003cimg src=\"https://img.imgdb.cn/item/604b88715aedab222cebf613.jpg\"/\u003e \u003c/div\u003e \u003cdiv class=\"img img5\"\u003e \u003cimg src=\"https://img.imgdb.cn/item/604b88715aedab222cebf60b.jpg\"/\u003e \u003c/div\u003e \u003cdiv class=\"img img6\"\u003e \u003cimg src=\"https://img.imgdb.cn/item/604b88715aedab222cebf608.jpg\"/\u003e \u003c/div\u003e \u003cdiv class=\"img img7\"\u003e \u003cimg src=\"https://img.imgdb.cn/item/604b88715aedab222cebf604.jpg\"/\u003e \u003c/div\u003e \u003cdiv class=\"img img8\"\u003e \u003cimg src=\"https://img.imgdb.cn/item/604b88595aedab222cebe8ac.jpg\"/\u003e \u003c/div\u003e \u003cdiv class=\"img img9\"\u003e \u003cimg src=\"https://img.imgdb.cn/item/604b88595aedab222cebe8a8.jpg\"/\u003e \u003c/div\u003e \u003c/div\u003e \u003c/div\u003e \u003c/div\u003e \u003c/body\u003e \u003c/html\u003e   ","description":"","tags":["记录","html","CSS"],"title":"立体相册","uri":"/%E7%AB%8B%E4%BD%93%E7%9B%B8%E5%86%8C/"},{"categories":["编程"],"content":"在程序员的1-3年阶段，我们需要不断努力的学习并积累知识点，那么每个阶段都需要具备什么条件呢？请看下面：\n🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥\n10k面试题 1.抽象类和接口的关系和区别，以及你在实际开发过程中是怎样使用的？  查看提示 答案后续更新...  2.你知道反射机制和动态代理吗？  查看提示 答案后续更新...  3.一个线程连续两次调用start方法会发生什么？简单谈谈线程的几种状态？  查看提示 答案后续更新...  4.springmvc实现原理？  查看提示 答案后续更新...  5.mybatis中#$的区别？  查看提示 答案后续更新...  6.你知道设计模式吗？在实际运用中你会怎样去运用它？比如我这里有个策划打折活动，比如VIP，普通用户，顾客分别打不一样的折扣，你会用什么设计模式？  查看提示 答案后续更新...  7.你知道索引失效吗？举例看看？  查看提示 答案后续更新...  8.多态在实际项目中的使用？  查看提示 答案后续更新...  9.你知道Spring IOC 吗？Spring 是怎样创建对象的？  查看提示 答案后续更新...  10.你知道缓存机制不？  查看提示 答案后续更新...  11.你的项目中有用到数据库分库分片吗？数据库分库分片规则？  查看提示 答案后续更新...  12.在实际中你会怎样对sql语句进行优化？  查看提示 答案后续更新...  13.常见的数据结构有哪些？在Java中是怎样使用它们的？  查看提示 答案后续更新...  14.JVM原理你知道吗？有没有自己调优过？  查看提示 答案后续更新...  15.看你的项目里用到了SpringBoot，谈谈你对SpringBoot的理解？  查看提示 答案后续更新...  16.你项目里用到了 rocket MQ，那你知道rabbit MQ、rocket MQ和kafka它们之间的区别吗？  查看提示 答案后续更新...  17.redis常用场景有哪些？你的项目中主要是使用redis干嘛的？  查看提示 答案后续更新...  18.有自己部署过redis吗？redis是如何实现高可用的？  查看提示 答案后续更新...  19.了解mysql的读写分离吗？是如何实现高可用的？  查看提示 答案后续更新...  20.Exception和Error的关系和区别？  查看提示 答案后续更新...  21.基本数据类型转换为String时你有几种方法，分别是什么？  查看提示 答案后续更新...  22.如何利用JDK不依赖外部工具，实现一个简单的缓存机制？请简述用到的技术和思路？  查看提示 答案后续更新...  23.你项目中是怎样用到事物的，分布式锁呢？  查看提示 答案后续更新...  24.Zookeeper有哪些运用场景？  查看提示 答案后续更新...  String 可能会问到的 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  // 1、== 和 equals的区别？ // 建议从基本数据类型和引用数据类型以及Object和String的equals来大致说 // 2、下面代码的运行结果是？ String str1 = \"Hello World\"; String str2 = \"Hello\" + \" World\"; // 两个常量池的字面拼接值还是在常量池中 System.out.println(str1 == str2); // true  // 3、下面代码运行的结果是？ String str1 = \"Hello World\"; // 常量池 String str2 = \"Hello\"; str2 += \" World\"; // 操作了str2 是一个变量，变量是存在于 堆中的 System.out.println(str1 == str2); // false  // 4、下面代码运行的结果是？ String str1 = \"Hello World\"; String str2 = \" World\"; String str3 = \"Hello\" + str2; System.out.println(str1 == str3); // false  // 5、下面代码的运行结果是？ String str1 = \"Hello World\"; final String str2 = \" World\"; String str3 = \"Hello\" + str2; System.out.println(str1 == str3); // true  // 6、下面代码的运行结果是？ String str1 = \"Hello World\"; final String str2 = new String(\" World\"); //虽然用final修饰了，但是因为是采用的构造函数来实例化的，所以本身就存在于堆内存中，本身就是一个变量了 String str3 = \"Hello\" + str2; System.out.println(str1 == str3); // false  // 7、下面代码的运行结果是？ String str1 = \"Hello World\"; String str2 = \"Hello\"; String str3 = \" World\"; String str4 = str2 + str3; System.out.println(str4 == str1); // false System.out.println(str4.intern() == str1); // true intern相当于是从常量池中查找是否有该值，若有则返回     🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀\n15k面试题 1.IO/NIO的区别，为什么要用NIO，使用IO中的Buffered也能实现NIO的面向缓冲，什么情况下用NIO？  查看提示 答案后续更新...  2.熟悉的排序算法有哪些？快速排序算法的实现原理？  查看提示 答案后续更新...  3.HashMap与ConcurrentHashMap有什么区别？HashMap的存储结构？  查看提示 答案后续更新...  4.vector、ArrayList和LinkedList区别及存储性能？  查看提示 答案后续更新...  5.线程实现的几种方式，有什么区别，一般用哪个，为什么？  查看提示 答案后续更新...  6.多线程中线程池怎么样使用及其实现原理？  查看提示 答案后续更新...  7.volatile关键字的作用是什麽？  查看提示 答案后续更新...  8.synchronized关键字的作用，使用该关键字后保证同步了，同步代码块与同步方法有什么区别？  查看提示 答案后续更新...  9.一个线程可以多次start吗？会报错吗？  查看提示 答案后续更新...  10.Spring AOP IOC实现原理？  查看提示 答案后续更新...  11.Spring中的事物的传播方式怎样实现的？  查看提示 答案后续更新...  12.Spring中事物实现的原理？  查看提示 答案后续更新...  13.为什么要使用数据库索引，数据库索引有哪些？索引的底层原理是什么？  查看提示 答案后续更新...  14.sql查询缓慢怎么处理？sql优化方案有哪些？explain用过吗？  查看提示 答案后续更新...  15.数据库中的锁有几种？比如行锁，表锁等了解吗？  查看提示 答案后续更新...  16.数据库为什么要使用事物？事物的原理是什么？  查看提示 答案后续更新...  17.数据库分库分表的方法，垂直分还是水平分，根据哪些来分？  查看提示 答案后续更新...  18.count(1) count(5) count(*)有什么区别，100万条数据的效率如何？  查看提示 答案后续更新...  19.solr搜索实现原理，使用的排序算法是什么？怎样实现快速查询？  查看提示 答案后续更新...  20.3次握手的原理是什么？  查看提示 答案后续更新...  21.动态代理实现原理是什么和动态代理使用的方法、类有哪些？  查看提示 答案后续更新...  22.redis的数据结构有哪些？  查看提示 答案后续更新...  23.虚拟机了解多少？  查看提示 答案后续更新...  24.Spring默认是单例还是多例的？  查看提示 答案后续更新...  25.常用的队列有哪些？分别是什么情况下使用？  查看提示 答案后续更新...  26.你知道的线程安全的类有哪些，方法有哪些？  查看提示 答案后续更新...  27.数据库的乐观锁和悲观锁的原理及使用？  查看提示 答案后续更新...  28.对GC了解多少？  查看提示 答案后续更新...  29.堆和栈的区别，堆中存放什么，栈中存放什么？  查看提示 答案后续更新...  30.用过的中间件有哪些？  查看提示 答案后续更新...    💄💄💄💄💄💄💄💄💄💄💄💄💄💄💄💄\n20k面试题 1.你认为的“大规模高并发访问的Web”有哪些呢？请举例2个知名的网站？  查看提示 答案后续更新...  2.你开发过的核心功能有哪些呢？  查看提示 答案后续更新...  3.如果让你对外开发一个接口，你会考虑哪些因素？  查看提示 答案后续更新...  4.设计数据库的时候会考虑哪些因素，怎样去建表？  查看提示 答案后续更新...  5.说说负载均衡，缓存，文件数据库技术的心得和要点？  查看提示 答案后续更新...  6.性能评估机制有哪些方面呢，你有这方面的经验和心得吗？  查看提示 答案后续更新...  7.精通UML以及熟练使用一种或多种建模工具  查看提示 答案后续更新...  8.你常去的技术网站是什么？工作中用过什么辅助软件呢？  查看提示 答案后续更新...    ","description":"","tags":["Java","面试"],"title":"Java面试题(一)","uri":"/java%E9%9D%A2%E8%AF%95%E9%A2%98%E4%B8%80/"},{"categories":["笔记"],"content":"精确搜索：双引号  精确搜索就是在你要搜索的词上，加上双引号，这时google就会完全的匹配你所要搜索的字符串 \"今日黄瓜\"\n 站内搜索：site  例如我想在stackoverflow中搜索spring boot，如下输入即可： site:stackoverflow.com spring boot 【输不输入请求协议均可，当然你也可以这样: site:https://stackoverflow.com spring boot】\n 通配符搜索：*  例如我想搜索所有包含 熔炉 的网页，此时就可以这样搜索： * 熔炉 ， 此时就会出现所有开头任意字符串，但是一定包含关键词熔炉的结果。【可以想象sql语句中的模糊匹配哦】\n 过滤掉某些条件：-  例如我想搜索一下 人口，但是想排除掉包含有中国的字样，可以如下使用： 人口 -中国\n 搜索文档：filetype  例如我想搜索关于 golang 语言的pdf文档，应该如下搜索： filetype:pdf golang\n ","description":"","tags":["记录"],"title":"Google搜索指南","uri":"/google%E6%90%9C%E7%B4%A2%E6%8C%87%E5%8D%97/"},{"categories":["随笔"],"content":"之前不错的一家公司 爱你 最近看了一些之前的短视频，赶紧挺扎心的啊\n ---\r ---\r ---\r ---  ---  ---\r古文魅力  ---\r ---\r ---\r ---\r ---\r ---\r ---\r ---\r ---\r ---\r ---\r ---\r ---\r ---\r ---\r ---\r ---\r ---\r ---\r ---\r ---\r ---\r ---\r 点滴  ---\r ---\r ---\r ---\r 学驾照ing 科目一98分，科目二考了两次，第一次直接灭火三次挂了，还好第二次机会满分通过，科目三满分过，科目四100分，总算是考下来了。\n看看某人的囧哈 如今只能是回忆一下了，毕竟都过去了，一切都随风而去了。\n","description":"","tags":["心情","回忆"],"title":"曾经","uri":"/%E6%9B%BE%E7%BB%8F/"},{"categories":["编程"],"content":"springmvc 的配置 springmvc配置文件需要配置的内容\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  \u003c!--配置包扫描--\u003e \u003ccontext:component-scan base-package=\"com.latinos.*\"/\u003e \u003c!--开启springmvc注解驱动--\u003e \u003cmvc:annotation-driven/\u003e \u003c!--配置视图解析器：是为了在url上不写 pages InternalResourceViewResolver--\u003e \u003cbean id=\"internalResourceViewResolver\" class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"\u003e \u003c!--配置前缀--\u003e \u003cproperty name=\"prefix\" value=\"/pages/\"/\u003e \u003c!--配置后缀--\u003e \u003cproperty name=\"suffix\" value=\"\"/\u003e \u003c/bean\u003e \u003c!--配置文件上传 CommonsMultipartResolver--\u003e \u003cbean id=\"multipartResolver\" class=\"org.springframework.web.multipart.commons.CommonsMultipartResolver\"\u003e \u003c!--配置默认编码--\u003e \u003cproperty name=\"defaultEncoding\" value=\"UTF-8\"/\u003e \u003c!--配置所有文件的总上传大小--\u003e \u003cproperty name=\"maxUploadSize\" value=\"10485760\"/\u003e \u003c/bean\u003e \u003c!--配置定时器任务（可以暂时不写）--\u003e   spring 的配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  \u003c!--配置读取jdbc.properties配置文件的工具类 PropertyPlaceholderConfigurer--\u003e \u003cbean id=\"propertyPlaceholderConfigurer\" class=\"org.springframework.beans.factory.config.PropertyPlaceholderConfigurer\"\u003e \u003c!--配置 jdbc.properties 的读取位置 如果是 资源文件，路径就是用 . 隔开的， 当处于 resouces 直接根目录下的，就是 classpath，若有子包的话，就是 classpath* --\u003e \u003cproperty name=\"location\" value=\"classpath:jdbc.properties\"/\u003e \u003c/bean\u003e \u003c!--配置数据源及数据库连接池 BasicDataSource--\u003e \u003cbean id=\"basicDataSource\" class=\"org.apache.commons.dbcp.BasicDataSource\"\u003e \u003cproperty name=\"driverClassName\" value=\"${driverClassName}\"\u003e\u003c/property\u003e \u003cproperty name=\"url\" value=\"${url}\"/\u003e \u003cproperty name=\"username\" value=\"${username}\"/\u003e \u003cproperty name=\"password\" value=\"${password}\"/\u003e \u003c/bean\u003e \u003c!--读取书写sql语句的xml文件的位置 SqlSessionFactoryBean--\u003e \u003cbean id=\"sqlSessionFactoryBean\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"\u003e \u003c!--注入数据源--\u003e \u003cproperty name=\"dataSource\" ref=\"basicDataSource\"/\u003e \u003c!--指定xml文件的存放位置--\u003e \u003cproperty name=\"mapperLocations\" value=\"classpath*:com/latin/mapper/*.xml\"\u003e\u003c/property\u003e \u003c!--指定mybatis主配置文件--\u003e \u003cproperty name=\"configLocation\" value=\"classpath:mybatis.xml\"/\u003e \u003c/bean\u003e \u003c!--读取dao层接口类，将dao层与对应的xml文件关联 MapperScannerConfigurer--\u003e \u003cbean id=\"mapperScannerConfigurer\" class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"\u003e \u003c!--指定dao接口类的位置--\u003e \u003cproperty name=\"basePackage\" value=\"com.latin.mapper\"/\u003e \u003c/bean\u003e   mybatis 的配置 1 2 3 4 5 6 7 8  \u003c!--配置别名--\u003e \u003c!--配置PageHelper插件--\u003e \u003cplugins\u003e \u003cplugin interceptor=\"com.github.pagehelper.PageHelper\"\u003e \u003cproperty name=\"dialect\" value=\"mysql\"/\u003e \u003c/plugin\u003e \u003c/plugins\u003e   web.xml 的配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  \u003c!--配置默认访问首页--\u003e \u003cwelcome-file-list\u003e \u003cwelcome-file\u003e/pages/front/index.jsp\u003c/welcome-file\u003e \u003c/welcome-file-list\u003e \u003c!--配置处理中文乱码的过滤器类--\u003e \u003cfilter\u003e \u003cfilter-name\u003echaracterEncodingFilter\u003c/filter-name\u003e \u003cfilter-class\u003eorg.springframework.web.filter.CharacterEncodingFilter\u003c/filter-class\u003e \u003cinit-param\u003e \u003cparam-name\u003eencoding\u003c/param-name\u003e \u003cparam-value\u003eUTF-8\u003c/param-value\u003e \u003c/init-param\u003e \u003c/filter\u003e \u003cfilter-mapping\u003e \u003cfilter-name\u003echaracterEncodingFilter\u003c/filter-name\u003e \u003curl-pattern\u003e/*\u003c/url-pattern\u003e \u003c/filter-mapping\u003e \u003c!--配置监听器，读取applicationContext.xml文件：ContextLoaderListener--\u003e \u003ccontext-param\u003e \u003cparam-name\u003econtextConfigLocation\u003c/param-name\u003e \u003cparam-value\u003eclasspath:applicationContext.xml\u003c/param-value\u003e \u003c/context-param\u003e \u003clistener\u003e \u003clistener-class\u003eorg.springframework.web.context.ContextLoaderListener\u003c/listener-class\u003e \u003c/listener\u003e \u003c!--配置springmvc的核心类--\u003e \u003cservlet\u003e \u003cservlet-name\u003edispatcherServlet\u003c/servlet-name\u003e \u003cservlet-class\u003eorg.springframework.web.servlet.DispatcherServlet\u003c/servlet-class\u003e \u003cinit-param\u003e \u003cparam-name\u003econtextConfigLocation\u003c/param-name\u003e \u003cparam-value\u003eclasspath:springmvc.xml\u003c/param-value\u003e \u003c/init-param\u003e \u003cload-on-startup\u003e1\u003c/load-on-startup\u003e \u003c/servlet\u003e \u003cservlet-mapping\u003e \u003cservlet-name\u003edispatcherServlet\u003c/servlet-name\u003e \u003curl-pattern\u003e*.do\u003c/url-pattern\u003e \u003c/servlet-mapping\u003e \u003c!--配置错误页面--\u003e \u003cerror-page\u003e \u003cerror-code\u003e404\u003c/error-code\u003e \u003clocation\u003e/pages/error/404.jsp\u003c/location\u003e \u003c/error-page\u003e    柳梢青·茅舍疏篱 -- 宋代：杨无咎   茅舍疏篱。半飘残雪，斜卧低枝。可更相宜，烟笼修竹，月在寒溪。宁宁伫立移时。判瘦损、无妨为伊。谁赋才情，画成幽思，写入新诗。\n ","description":"","tags":["SpringMvc"],"title":"SpringMvc框架的基本配置","uri":"/springmvc%E6%A1%86%E6%9E%B6%E7%9A%84%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/"},{"categories":["编程"],"content":"Redis 简介 基于内存进行存储，支持key-value的存储形式，底层是用C语言编写的\n基于key-value形式的数据字典，结构非常简单，没有数据表的概念，直接用键值对的形式完成数据的管理，Redis支持5种数据类型：\n 字符串 列表 集合 有序集合 哈希  安装 Redis 下载 https://redis.io/download\n解压，并在本地硬盘任意位置创建文件夹，在其中创建3个子文件夹  bin：放置启动 redis 的可执行文件 db：放置数据文件 etc：放置配置文件，设置redis服务的端口、日志文件位置、数据文件位置等  同时将解压后（或者安装后的所有文件）都拷贝到创建的这个文件夹下面\n启动redis服务 打开终端，进入到上一步新建的目录下面\n先启动server：\n1  ./redis-server.exe ./redis.windows.conf   当然你也可以将server 注册为一个服务，但是我不建议这样做\n再启动 client：\n1  ./redis-cli.exe   对数据进行操作：\n1 2  set key value get key   退出client：shutdown\nSpring Boot整合Redis spring data Redis 操作 redis\n 1、新建 maven 工程，添加如下依赖：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003cgroupId\u003ecom.example\u003c/groupId\u003e \u003cartifactId\u003espringbootredis\u003c/artifactId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c!-- 切记先引入springboot工程的 parent--\u003e \u003cparent\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-parent\u003c/artifactId\u003e \u003cversion\u003e2.3.1.RELEASE\u003c/version\u003e \u003c/parent\u003e \u003cdependencies\u003e \u003c!-- web依赖--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- springboot 整合redis，使用的是spring data 来操作redis --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-data-redis\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- 连接池是 apache 提供的 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.commons\u003c/groupId\u003e \u003cartifactId\u003ecommons-pool2\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- lombok 简化代码，主要是简化entity 与 数据库的映射代码--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.projectlombok\u003c/groupId\u003e \u003cartifactId\u003elombok\u003c/artifactId\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/project\u003e    2、创建实体类，必须实现序列化接口，否则无法存入redis缓存数据库  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  package com.example.entity; import lombok.Data; import java.io.Serializable; import java.util.Date; /** * @author latin-xiao-mao * @date 2020/7/17 19:26 * @description 因为要存入 redis 中，故必须需要实现 Serializable 接口 * 因为是给内存中存，所以必须完成序列化操作 * @className Student */ @Data // 使用lombok 简化代码（比如getter/setter） public class Student implements Serializable { private String name; private Integer id; private Double score; private Date birthday; }    3、创建控制器  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  package com.example.controller; import com.example.entity.Student; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RestController; /** * @author latin-xiao-mao * @date 2020/7/17 19:43 * @description * @className StudentHandler */ @RestController public class StudentHandler { //redis为我们提供了一个操作data的操作对象 \t@Autowired // 启动时会自动为我们创建一个实例对象，只需要注入即可 \tprivate RedisTemplate redisTemplate; /** * 往redis中存入数据对象 * @param student * 这里为什么要写 @RequestBody呢，因为我们要将客户端传过来的 JSON对象 转换为Java实体类对象 */ @PostMapping(\"/set\") public void set(@RequestBody Student student){ // 然后我们直接通过 redisTemplate 来操作数据，但是必须先调用 opsForValue()方法（此方法将key，value直接封装成一个对象来操作） \tredisTemplate.opsForValue().set(\"student\", student); } @GetMapping(\"/get/{key}\") // 表明 /get/ 后面的是一个 变量 \tpublic Student get(@PathVariable(\"key\") String key){ // pathvariable 通过变量名称key来获取实际的值  return (Student) redisTemplate.opsForValue().get(key); } }    4、创建配置文件application.yml  1 2 3 4 5  spring:redis:database:0# 0表示统一的数据库，一般不用修改host:127.0.0.1port:6379   5、创建启动类  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  package com.example; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; /** * @author latin-xiao-mao * @date 2020/7/17 19:57 * @description * @className Application */ @SpringBootApplication public class Application { public static void main(String[] args) { // 启动 \tSpringApplication.run(Application.class, args); } }   Redis 如何存储5种数据类型  字符串  1 2 3 4 5 6 7  @GetMapping(\"/{key}\") public String stringTest(@PathVariable(\"key\") String key){ redisTemplate.opsForValue().set(key, \"hello world!!!\"); String result = (String) redisTemplate.opsForValue().get(key); return result; }    列表  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  /** * 列表的存取，redis列表实际相当于java 中的list */ @GetMapping(\"/list\") public List\u003cObject\u003e listTest(){ // 存 \tListOperations\u003cString, Object\u003e listOperations = redisTemplate.opsForList(); // List 数据类型就用 opsForList \tlistOperations.leftPush(\"list\", \"hello\"); listOperations.leftPush(\"list\", \"world\"); listOperations.leftPush(\"list\", 123); // 取 \tList\u003cObject\u003e list = listOperations.range(\"list\", 0, 2); return list; }    集合  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  /** * redis中的集合 实际相当于Java中的 set，无序不重复 * @return */ @GetMapping(\"/set\") public Set\u003cObject\u003e setTest(){ // setOperations key一般是 string类型，value取决于你实际的需求 \tSetOperations\u003cString, Object\u003e setOperations = redisTemplate.opsForSet(); setOperations.add(\"set\", \"hello\"); // 测试是否不可重复 \tsetOperations.add(\"set\", \"hello\"); setOperations.add(\"set\", \"world\"); setOperations.add(\"set\", \"world\"); setOperations.add(\"set\", 0); setOperations.add(\"set\", 0); // 取 \tSet\u003cObject\u003e set = setOperations.members(\"set\"); return set; }    有序集合  1 2 3 4 5 6 7 8 9 10 11 12 13  /** * 有序集合 zset * @return */ @GetMapping(\"/zset\") public Set\u003cString\u003e zsetTest(){ ZSetOperations\u003cString, String\u003e zSet = redisTemplate.opsForZSet(); zSet.add(\"zset\", \"hello\", 1); // 第三个参数是，存储的位置，可以通过这个控制它的顺序 \tzSet.add(\"zset\", \"world\", 2); zSet.add(\"zset\", \"java\", 3); Set\u003cString\u003e set = zSet.range(\"zset\", 0, 2); return set; }    哈希  传统的HashMap是由key，value组成的，格式为：\nHashMap\u003ckey, value\u003e\n而redis中的 哈希是下面格式的，它多了一个参数key：\nHashOperations\u003ckey, hashkey, value\u003e\nkey：每一组数据的id\nhashkey和value是一组完整的 HashMap数据，通过key来区分不同的HashMap\n1 2 3 4 5 6 7 8 9 10 11 12 13  /** * 哈希，需要三个参数：key,hashKey,value * @return */ @GetMapping(\"/hash\") public String hashTest(){ HashOperations\u003cString, String, String\u003e hashOperations = redisTemplate.opsForHash(); // 第一个key，取出一组 hashMap，第二个key，取出value \thashOperations.put(\"key\", \"hashKey\", \"hello\"); String str = hashOperations.get(\"key\", \"hashKey\"); return str; }   ","description":"","tags":["SpringBoot","Redis"],"title":"SpringBoot整合Redis","uri":"/springboot%E6%95%B4%E5%90%88redis/"},{"categories":["笔记"],"content":"将 spring boot 应用程序打包成 jar 包 我们使用 spring boot 的 maven 插件来构建管理整个应用程序，使用 mvn package 将应用程序打包成一个 jar 包\n将 该 jar 包上传到 服务器 上传到服务器大致有两种方式（常见的）：1）通过 xftp 这种方式；2）本文将要介绍的这种，我不太建议使用 xftp，因为它太常见了，不新奇， 说说第二种方式吧：首先我们在 linux 服务器上，下载 lrzsz 插件，命令为：yum -y install lrzsz,然后上传文件就输入命令：rz -y ，-y 表示强制覆盖原有文件（建议使用），rz 表示上传，当然了，sz 就表示下载喽。之后就会打开一个 windows 的文件资源管理器窗口，你选择目标 jar 包即可实现上传（前提，选择好你的上传目录）\n运行 上传到服务器的指定位置了，接下来就是如何运行了！ 我们都知道，java 程序在你本地运行时就是选择好入口 main，然后运行即可。但是在 linux 上就不是那么简单了。 大致呢有两种：一种是直接手动启动；一种是通过写一个脚本文件来启动。 直接启动： java -jar 目标.jar \u003e\u003e catalina.out 2\u003e\u00261 \u0026,什么意思呢？就是将 tomcat（spring-boot-starter-web 自带 tomcat） 的启动内容 标准错误流重定向到标准输出流(2 \u003e\u00261)，并且以在后台运行的形式去运行(\u0026)。\n脚本启动 编写启动脚本\n1 2 3 4 5 6 7 8 9  #!/bin/bash PROJECTNAME=目标jar名称(不需要带.jar) pid=`ps -ef |grep $PROJECTNAME |grep -v \"grep\" |awk '{print $2}'` if [ $pid ]; then ​ echo \"$PROJECTNAMEis running and pid=$pid\" else echo \"Start success to start $PROJECTNAME....\" nohup java -jar 目标.jar \u003e\u003e catalina.out 2\u003e\u00261 \u0026 fi   在该 .sh(脚本文件)中，使用到了命令 nohup java -jar ... nohup 就是 no hangup（不挂起），即 即使用户登出， 关闭终端后，该进程还会继续运行；采用 nohup 命令后，那么就会在当前脚本所在的同级目录下生成一个 nohup.out 的文件， 该文件就记录了整个应用启动过程以及之后运行中的所有日志内容（因为我们是将 2 标准错误 作为输出内容的， 而标准错误默认是包括所有的输出内容+错误内容）。之后你只需要运行这个脚本即可启动应用程序啦：./start.sh， 如果你想查看一下日志内容，你可以输入：vi nohup.out，或者你只想查看最后几行内容：tail -f nohup.out即可。\n脚本关闭 编写关闭脚本: 其实我们一般是不需要关闭脚本的，因为我们通常是这样操作的：进入到该应用程序所在的目录： ps aux | grep java 或 ps -ef | grep java 二者并没有什么太大的区别，看你喜欢用哪个命令了， 然后找到该应用程序的 pid, 然后 kill -g 该pid 就杀死这个进程了。但是其实这样很麻烦， 你习惯了还好，一般我还是建议你使用 关闭脚本的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  #!/bin/bash PROJECTNAME=目标 pid=`ps -ef |grep $PROJECTNAME |grep -v \"grep\" |awk '{print $2}' ` if [ $pid ]; then ​ echo \"$PROJECTNAMEis running and pid=$pid\" ​ kill -9 $pid ​ if [[ $? -eq 0 ]];then ​ echo \"sucess to stop $PROJECTNAME\" ​ else ​ echo \"fail to stop $PROJECTNAME\" ​ fi fi   一般目录结构就是如下图所示： 我实际中用的这个启动脚本内容如下：\nps:至于有人说的可能需要在 pom.xml 中指定 入口类，大家也可以这样做，请自行百度。\n","description":"","tags":["SpringBoot"],"title":"SpringBoot程序Jar包部署","uri":"/springboot%E7%A8%8B%E5%BA%8Fjar%E5%8C%85%E9%83%A8%E7%BD%B2/"},{"categories":["编程"],"content":"Vue + Element UI 先在上一期的文章基础上引入 element-ui 依赖\n添加 Element-UI依赖  yarn add element-ui\n在 main.js 中注册组件，并使用 选择引入布局 \n选择一个你喜欢的布局，然后粘贴代码到你的 App.vue 文件中（放入你想要的目标文件中即可）\n启动前端项目，浏览器查看效果  现在呐，我们的菜单是写死的，并不符合我们的实际需求，因此我们需要修改为动态加载菜单\n使用 Vue-router来动态构建左侧菜单 先来创建几个示例页面 这时我们来访问页面，会发现有个问题\n当我们的访问路径是：http://localhost:8080/pageTwo 或者 http://localhost:8080/pageOne 时是没有问题的，但是当是 http://localhost:8080/ 时会出现嵌套页面App.vue\n这是我们需要解决的地方\n那么怎么解决这个问题呢？首先我们需要来分析一下 App.vue 文件\nrouter-view 分析 我们当前的 应用程序是 spa 应用，原理就是在于这个 router-view。而这个和我们的 /src/router/index.js 相对应；当我们的访问路径是 / 时，路由视图会渲染如下页面：\n而在 App.vue 文件中本身就是有内容的，这样就会出现嵌套了。\n因此我们需要改变默认路由视图\n编辑 /src/router/index.js 文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  const routes = [ { path: '/', name: '导航一', component: App, children: [ { path: '/pageOne', name:　'页面一', component: PageOne }, { path: '/pageTwo', name: '页面二', component: PageTwo } ] }, { path: '/navigation', name: '导航二', component: App, children: [ { path: '/pageThree', name: '页面三', component: PageThree }, { path: '/pageFour', name: '页面四', component: PageFour } ] } ]   接着我们修改 App.vue 文件，因为我们不能将 侧边菜单栏写死啊，需要根据上面的路由动态生成菜单栏\n因为我们需要遍历循环 /src/router/index.js 中的 routes 数组，所以通过上面的写法就可以实现了，同时菜单的名字也只能是动态获取 routes 数组里面的name属性了\n但是现在又有一个问题了，就是上图显示的这两个导航同时会打开关闭，也就是没有给导航设置 index 属性值，所以我们就给他们设置一下index：\nMenu 与 router 的绑定   标签添加 router 属性 在页面中添加  标签，它是一个容器，可以动态渲染你选择的 router 。  标签的 index 就是要跳转的 router。  还有一个小问题就是：当地址栏是 /pageOne 时，菜单栏的 页面一 并没有出现选中的样式，这不符合我们的要求，如下修改：\n有如上思路后，我们再修改代码：\n页面一替换为我们要展示的数据 添加分页 https://element.eleme.cn/#/zh-CN/component/pagination，复制代码到页面一中\n[注意：Vue 只允许有一个div 的根节点，因此如果有两个容器的话，必须包在一个div下]\n1 2 3 4 5 6 7 8 9 10  \u003c!-- 添加分页 --\u003e \u003cel-pagination background layout=\"prev, pager, next\" page-size=\"5\" :total=\"50\" @current-change=\"page\" \u003e \u003c/el-pagination\u003e   设置每页的大小，同时添加 触发方法 @current-change\n后端实现分页查询 由于我们使用的是 JPA，而其提供了一个 findAll 的重载方法就是关于分页的\n1 2 3 4 5 6 7 8 9 10  import org.springframework.data.domain.Page; import org.springframework.data.domain.PageRequest; import org.springframework.data.domain.Pageable; @GetMapping(\"/findAll/{page}/{size}\") public Page\u003cBook\u003e findAll(@PathVariable(\"page\") Integer page, @PathVariable(\"size\") Integer size){ Pageable pageable = PageRequest.of(page-1, size); return bookRepository.findAll(pageable); }   由于 Pageable 是一个接口，这里我们用其实现类的静态方法构造实例\n添加数据 后端修改 JPA 已经封装了 save 方法，所以直接使用即可\n1 2 3 4 5  @PostMapping(\"/save\") public Book save(@RequestBody Book book){ // 因为是post请求，所以需要使用 @RequestBody 注解将 json 数据转成 java对象  return bookRepository.save(book); }   注意 @RequestBody 的作用\n前端修改 从 element ui 官网上，查看 form 表单的使用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93  \u003ctemplate\u003e \u003cel-form :model=\"ruleForm\" :rules=\"rules\" ref=\"ruleForm\" label-width=\"100px\" class=\"demo-ruleForm\"\u003e \u003cel-form-item label=\"书名\" prop=\"title\"\u003e \u003cel-input v-model=\"ruleForm.title\"\u003e\u003c/el-input\u003e \u003c/el-form-item\u003e \u003cel-form-item label=\"作者\" prop=\"author\"\u003e \u003cel-input v-model=\"ruleForm.author\"\u003e\u003c/el-input\u003e \u003c/el-form-item\u003e \u003cel-form-item label=\"内容简介\" prop=\"abs\"\u003e \u003cel-input v-model=\"ruleForm.abs\"\u003e\u003c/el-input\u003e \u003c/el-form-item\u003e \u003cel-form-item\u003e \u003cel-button type=\"primary\" @click=\"submitForm('ruleForm')\"\u003e提交\u003c/el-button\u003e \u003cel-button @click=\"resetForm('ruleForm')\"\u003e重置\u003c/el-button\u003e \u003c/el-form-item\u003e \u003c/el-form\u003e \u003c/template\u003e \u003cscript\u003e export default { name: \"Add\", data() { return { ruleForm: { title: '', author: '', abs: '' }, rules: { title: [ { required: true, message: '请输入书名', trigger: 'blur' } ], author: [ { required: true, message: '请输入作者', trigger: 'blur' } ], abs: [ { required: true, message: '请输入内容简介', trigger: 'blur' } ] } }; }, methods: { submitForm(formName) { const _this = this; this.$refs[formName].validate((valid) =\u003e { if (valid) { //  axios.post('http://localhost:8181/book/save', _this.ruleForm).then( (resp) =\u003e { if (resp != null){ // _this.$message({  // message: '恭喜你，添加成功',  // type: 'success'  // });  _this.$alert('《' + _this.ruleForm.title + '》添加成功', '消息', { confirmButtonText: '确定', callback: action =\u003e { // 添加成功后，我们让页面自动跳转到 查询列表页面  // 同时让 页面跳转到 查询列表界面  // 先获取当前 路由，然后 push 进你的跳转目标页面  _this.$router.push('/list') } }); _this.resetForm(formName); // 添加成功后，我们让页面自动跳转到 查询列表页面  // 先获取 当前路由 对象，然后 push 进你跳转的目标页面 路由即可  // _this.$router.push('/list');  }else this.$message.error('添加失败'); }) } else { console.log('error submit!!'); return false; } }); }, resetForm(formName) { this.$refs[formName].resetFields(); } } } \u003c/script\u003e \u003cstyle scoped\u003e \u003c/style\u003e   修改数据 新建修改组件 Update.vue\n1    代码部分请参阅 https://github.com/latin-xiao-mao/springboot-vue-demo/tree/bookManage-crud-demo\n","description":"","tags":["SpringBoot","Vue"],"title":"SpringBoot+Vue之CRUD小demo(二)","uri":"/springboot-vue%E4%B9%8Bcrud%E5%B0%8Fdemo%E4%BA%8C/"},{"categories":["编程"],"content":"新建Vue3前端项目 先删除之前的vue2版本 npm uninstall -g vue-cli\n安装新的vue cli 包 npm install -g @vue/cli\n安装完成后使用命令：vue -V 检查是否安装成功\n构建项目 这里我们使用 vue3 提供的图形化界面操作：\n打开 cmder，输入 vue ui\n默认操作即可了\n安装依赖 yarn \n单页面spa应用 启动项目 yarn run serve\n单独运行成功，可以在 /src/views/ 自己再编写一个 Book.vue 页面，然后在 /src/router/index.js 中进行注册，使用即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58  \u003ctemplate\u003e \u003cdiv\u003e \u003ctable\u003e \u003ctr\u003e \u003ctd\u003e编号\u003c/td\u003e \u003ctd\u003e封面url\u003c/td\u003e \u003ctd\u003e书名\u003c/td\u003e \u003ctd\u003e作者\u003c/td\u003e \u003ctd\u003e出版日期\u003c/td\u003e \u003c/tr\u003e \u003ctr v-for=\"item in books\"\u003e \u003ctd\u003e{{item.id}}\u003c/td\u003e \u003ctd\u003e{{item.cover}}\u003c/td\u003e \u003ctd\u003e{{item.title}}\u003c/td\u003e \u003ctd\u003e{{item.author}}\u003c/td\u003e \u003ctd\u003e{{item.date}}\u003c/td\u003e \u003c/tr\u003e \u003c/table\u003e \u003c/div\u003e \u003c/template\u003e \u003cscript\u003e export default { name: \"Book\", data(){ // data是一个函数对象  return{ books: [ { id: 1, cover: 'https://i.loli.net/2019/04/10/5cadaa0d0759b.jpg', title: '红楼梦', author: '清婉儿', date: '2020-06-14' }, { id: 2, cover: 'https://i.loli.net/2019/04/10/5cadaa0d0759b.jpg', title: '那一夜', author: '卓文君', date: '2020-06-14' }, { id: 3, cover: 'https://i.loli.net/2019/04/10/5cadaa0d0759b.jpg', title: '飞上你的床', author: '上官飞燕', date: '2020-06-14' } ] } } } \u003c/script\u003e \u003cstyle scoped\u003e \u003c/style\u003e   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  import Vue from 'vue' import VueRouter from 'vue-router' import Home from '../views/Home.vue' // 引入 Book.vue import Book from '../views/Book' Vue.use(VueRouter) const routes = [ { path: '/', name: 'Home', component: Home }, { path: '/about', name: 'About', // 下面这是 vue3 的写法，这里我们还用vue2的写法注册组件  // this generates a separate chunk (about.[hash].js) for this route  // which is lazy-loaded when the route is visited.  component: () =\u003e import(/* webpackChunkName: \"about\" */ '../views/About.vue') }, { path: '/book', component: Book } ] const router = new VueRouter({ mode: 'history', base: process.env.BASE_URL, routes }) export default router   编写后端spring boot 代码 新建一个spring boot 工程 按照下图所示完成工程的创建 配置 application.yml 1 2 3 4 5 6 7 8 9 10 11 12 13  spring:datasource:url:jdbc:mysql://localhost:3306/virgin show?useUnicode=true\u0026characterEncoding=UTF-8\u0026serverTimezone=UTCusername:rootpassword:123456driver-class-name:com.mysql.cj.jdbc.Driverjpa:show-sql:trueproperties:hibernate:format_sql:trueserver:port:8181  注意这里采用这张表的数据\n编写实体类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  package com.springboot.demo.entity; import lombok.Data; import javax.persistence.Entity; import javax.persistence.Id; /** * @author: latinos-bub * @date: 2020/6/14 20:51 * @description: * @className: Book */ @Entity // 采用jpa依赖后，使用该注解，会自动将该类与数据库中的相同名字的表进行映射(注意：类与表名必须一样，首字母除外) @Data // lomback 自动提供getter/setter public class Book { @Id // 标注 数据库表中的主键字段 \tprivate Integer id; String cover; String title; String author; String date; // ... 这里的字段属性最多可以等于 表的字段，这里我们只取5个演示即可  }   编写接口 1 2 3 4 5 6 7 8 9 10 11 12 13  package com.springboot.demo.repository; import com.springboot.demo.entity.Book; import org.springframework.data.jpa.repository.JpaRepository; /** * @author: latinos-bub * @date: 2020/6/14 20:55 * @description: * @className: BookRepository */ public interface BookRepository extends JpaRepository\u003cBook, Integer\u003e { }   在接口中，我们这里只需要继承 JpaRepository\u003cT, id\u003e 接口即可，同时也不需要注解该接口是 @Repository，以为继承的接口中已经说明了\n编写测试接口类 我们打开 JpaRepository 会发现有好多方法，这里我们只测试一下 findAll 方法\n首先我们在 BookRepository 上右键：\n这样就新建了一个测试类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  package com.springboot.demo.repository; import org.junit.jupiter.api.Test; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; @SpringBootTest class BookRepositoryTest { @Autowired // 一定要将接口注入 \tprivate BookRepository book; @Test void findAll(){ System.out.println(book.findAll()); } }   运行测试即可 编写控制器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  package com.springboot.demo.controller; import com.springboot.demo.entity.Book; import com.springboot.demo.repository.BookRepository; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import java.util.List; /** * @author: latinos-bub * @date: 2020/6/14 21:53 * @description: * @className: BookHandler */ @RestController // restful 风格的 controller @RequestMapping(\"/book\") public class BookHandler { @Autowired // 一定要自动注入这个 接口 \tprivate BookRepository bookRepository; @GetMapping(\"/findAll\") // spring boot 独有的 \tpublic List\u003cBook\u003e findAll(){ return bookRepository.findAll(); } }   运行findAll 控制方法 打通 springboot 和 vue 先在 前端项目中安装 axios 模块 vue add axios\n安装成功后，会自动显示在 /src/plugins/axios.js\n改造 Book.vue 在 vue 的生命周期中，created 的初始化先于 data() 函数，因此我们就在 created 中实现数据的请求\n跨域配置 我们选择在spring boot 后端进行配置\n运行截图 ","description":"","tags":["SpringBoot","Vue"],"title":"SpringBoot+Vue之CRUD小demo(一)","uri":"/springboot-vue%E4%B9%8Bcrud%E5%B0%8Fdemo%E4%B8%80/"},{"categories":["笔记"],"content":"nginx是什么 Nginx 是一个高性能的 HTTP 和反向代理 web 服务器，同时也提供了 IMAP/POP3/SMTP 的服务 Nginx 特点是占有内存少，并发能力强 一般来说，如果我们在项目中引入了 Nginx ，我们的项目架构可能是这样： 在这样的架构中 ， Nginx 所代表的角色叫做负载均衡服务器或者反向代理服务器，所有请求首先到达 Nginx 上，再由 Nginx 根据提前配置好的转发规则，将客户端发来的请求转发到某一个 Tomcat 上去 那么这里涉及到两个概念：\n 负载均衡服务器 就是进行请求转发，降低某一个服务器的压力。负载均衡策略很多，也有很多层，对于一些大型网站基本上从 DNS 就开始负载均衡，负载均衡有硬件和软件之分，各自代表分别是 F5 和 Nginx （目前 Nginx 已经被 F5 收购），早些年，也可以使用 Apache 来做负载均衡，但是效率不如 Nginx ，所以现在主流方案是 Nginx 。 反向代理服务器 就是对于用户来说，用户只确定我请求的是某个位置的uri资源，但是这个资源是由谁来提供给我的，用户并不需要知道。就像我们日常打电话到110一样，你会有这样的疑问，全国都是打110，那么如果我身在北京打110会不会打到上海呢？哈哈，其实这就有点类似反向代理了，我们只需要知道我们打110，但是其真实的过程是网络默认在我们拨打的号码前加入了当地基站的前缀号码的缘故。  Nginx 的优势 在 Java 开发中，Nginx 有着非常广泛的使用，随便举几点：\n 使用 Nginx 做静态资源服务器：Java 中的资源可以分为动态和静态，动态需要经过 Tomcat 解析之后，才能返回给浏览器，例如 JSP 页面、Freemarker 页面、控制器返回的 JSON 数据等，都算作动态资源，动态资源经过了 Tomcat 处理，速度必然降低。对于静态资源，例如图片、HTML、JS、CSS 等资源，这种资源可以不必经过 Tomcat 解析，当客户端请求这些资源时，之间将资源返回给客户端就行了。此时，可以使用 Nginx 搭建静态资源服务器，将静态资源直接返回给客户端。 使用 Nginx 做负载均衡服务器，无论是使用 Dubbo 还是 Spirng Cloud ，除了使用各自自带的负载均衡策略之外，也都可以使用 Nginx 做负载均衡服务器。 支持高并发、内存消耗少、成本低廉、配置简单、运行稳定等。  Nginx 安装 因为我们日常的服务器都是选用的centos7的，所以在这里我就只介绍centos下nginx的安装，我们采用默认安装（即不主动设置安装目录）\n 下载nginx wget http://nginx.org/download/nginx-1.17.0.tar.gz  解压 tar -zxvf nginx-1.17.0.tar.gz   然后进入nginx-1.17.0目录 在编译安装之前，我们还需要安装两个依赖 yum -y install pcre-devel 和 yum -y install openssl openssl-devel  编译安装 依次执行如下命令： ./configure、 make、 make install 安装好之后，默认的安装位置是：/usr/local/nginx/sbin/nginx  启动nginx 进入sbin目录，启动：cd /usr/local/nginx/sbin、./nginx即可启动了 启动成功之后，我们访问本地的ip地址，即可看到如下界面： 看到如上页面，表示 Nginx 已经安装成功了 如果修改了 Nginx 配置，则可以通过如下命令重新加载 Nginx 配置文件：./nginx -s reload  题外话 大家都知道，现在我们的项目一般都是采用前后端分离的开发方式，而前后端分离的项目在部署时只有两种方式：\n 一种就是将前端项目打包编译之后，放到后端项目中（例如 Spring Boot 项目的 src/main/resources/static 目录下） 另外一种则是将前端打包之后的静态资源用 Nginx 来部署，后端单独部署只需要单纯的提供接口即可 一般在公司项目中，我们更多的是采用后者 在部署时，我们只需要将我们的项目打包成jar包，然后上传到服务器，然后执行该命令即可启动项目：nohup java -jar demo.jar \u003e demo.log \u0026 (demo.jar 是我们打包后的包名，这只是一个例子，你替换成你的包名即可) 这样这个项目的运行日志就写入到 demo.log 文件中了  ","description":"","tags":["Nginx","Centos"],"title":"Nginx在Centos7下的安装记录","uri":"/nginx%E5%9C%A8centos7%E4%B8%8B%E7%9A%84%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95/"},{"categories":["编程"],"content":"mysql中的触发器\n前言 这里呢，有两张表，分别是 CXY_TS_ORDER_TICKET  和 CXY_TS_ORDER_TICKET_STATUS 表，在 CXY_TS_ORDER_TICKET  表里面有一个get_status字段，现在呢，我们想在该字段发生变化时，在CXY_TS_ORDER_TICKET_STATUS` 表中，将该字段插入，并且记录变化时间以及发生变化的记录的主键。因此呢，我打算用触发器去实现这个需求\n实现 1 2 3 4 5 6 7 8 9 10 11 12 13  -- Created by util.you.com@gmail.com delimiter $$ CREATE TRIGGER `order_ticket_status_trigger` AFTER UPDATE ON `CXY_TS_ORDER_TICKET` FOR EACH ROW BEGIN DECLARE s1 INT(11); -- 声明变量，用于存入 CXY_TS_ORDER_TICKET 表的 get_status 字段值,id 字段值 \tDECLARE s2 INT(11); set s2 = new.id; -- 分别给 s1 和 s2 赋值 \tset s1 = new.get_status; IF((old.get_status != new.get_status) OR (old.get_status IS NULL \u0026\u0026 new.get_status IS NOT NULL)) THEN INSERT INTO `CXY_TS_ORDER_TICKET_STATUS`(`order_ticket_id`, `STATUS`, `insert_date_time`) VALUES(s2, s1, DATE_FORMAT(now(),'%Y-%m-%d %H:%i:%s')); END IF; END$$   解释  在 mysql 中，new、old都是内置的，分别表示一个字段发生变化前、后的值（当然也包括插入操作前后的变化），此处呢，因为我们需要根据 CXY_TS_ORDER_TICKET表的 get_status字段来插入记录到 CXY_TS_ORDER_TICKET_STATUS 表，因此呢，new 和 old 都取该字段即可。\nmysql 中的触发器呢，大致分为三类：insert 型、update 型、delete 型。\n何时触发该操作呢，又分为 after 和 before 型\n上示例子，就是一个触发器的大致模板，根据哪一张表的变化来触发该触发器，就 on 这张表即可了。\n ","description":"","tags":["MySql"],"title":"MySql触发器","uri":"/mysql%E8%A7%A6%E5%8F%91%E5%99%A8/"},{"categories":["编程"],"content":"Mybatis 中 resultMap 的使用  最关键的是明白 resultMap 的两个最重要的作用：\n-1 ：当你在 select 中，resultType 是一个 Entity(或 Model等 pojo 时)，如果你的 sql 结果集字段与你的 pojo 属性名不一致时，这时可以通过 resultMap 起到 重新映射成你 pojo 中名字的结果集\n-2 : 第二个作用应该是使用量最多的一种，就是涉及到多对一的结果集映射或者一对多的结果集映射时\n 先说一下 resultMap 中 的 association 和 collection 的区别  association 用于 一对一 和 多对一的情况\ncollection 用于 一对一 和 一对多 的情况\n 举例如下 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  \u003c!--created by util.you.com@gmail.com search--\u003e \u003cselect id=\"search\" parameterType=\"java.util.Map\" resultMap=\"reFundList\"\u003e SELECT csr.id, csr.strategy_name, csr.remark, csr.`status`, sut.username, DATE_FORMAT(IFNULL(csr.insert_time, ''), '%Y-%m-%d %H:%i:%s') AS insert_time FROM `CL_STRATEGY_REFUND` AS csr LEFT JOIN `SYS_USER_TBL` AS sut ON sut.user_id = csr.insert_user_id WHERE csr.`status` = 1 \u003cif test=\"strategyName != null and strategyName != ''\"\u003e AND csr.strategy_name LIKE CONCAT('%',#{strategyName}, '%') \u003c/if\u003e ORDER BY csr.id DESC \u003cif test=\"offset != null and limit != null\"\u003e limit #{offset}, #{limit} \u003c/if\u003e ; \u003c/select\u003e \u003c!--created by util.you.com@gmail.com search 因为这里返回类型(即封装类型)是 Map，所以 property 的值就是 Map 封装的 key 名称--\u003e \u003cresultMap id=\"reFundList\" type=\"java.util.Map\"\u003e \u003cid column=\"id\" property=\"id\"/\u003e \u003cresult column=\"strategy_name\" property=\"strategyName\"/\u003e \u003cresult column=\"remark\" property=\"remark\"/\u003e \u003cresult column=\"username\" property=\"userName\"/\u003e \u003cresult column=\"insert_time\" property=\"insertTime\"/\u003e \u003ccollection property=\"ruleList\" javaType=\"ArrayList\" column=\"id\" select=\"selectReFundInfo\"/\u003e \u003c/resultMap\u003e \u003c!--created by util.you.com@gmail.com search--\u003e \u003cselect id=\"selectReFundInfo\" parameterType=\"java.lang.Integer\" resultType=\"java.util.Map\"\u003e select csrr.id, csrr.strategy_id, csrr.time_limit, csrr.fee_type, csrr.fee_value from `CL_STRATEGY_REFUND_REL` as csrr where csrr.`status` = 1 and csrr.strategy_id = #{id} \u003c/select\u003e    注意点请看下图 *   娱乐一下 ","description":"","tags":["Mybatis"],"title":"Mybatis中resultMap的使用","uri":"/mybatis%E4%B8%ADresultmap%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"categories":["编程"],"content":"HSSFWorkbook 介绍  开发中经常会遇到 Excel 的处理，在 Java 中，操作 excel 目前有两个主流框架，分别是：\n apache 的 poi   Apache POI [1] 是用Java编写的免费开源的跨平台的 Java API，Apache POI提供API给Java程式对Microsoft Office格式档案读和写的功能。POI为“Poor Obfuscation Implementation”的首字母缩写，意为“简洁版的模糊实现”。\n  Java Excel   Java Excel是一开放源码项目，通过它Java开发人员可以读取Excel文件的内容、创建新的Excel文件、更新已经存在的Excel文件。jxl 由于其小巧 易用的特点, 逐渐已经取代了 POI-excel的地位, 成为了越来越多的java开发人员生成excel文件的首选\n 这里提一下：HSSFWorkbook:是操作Excel2003以前（包括2003）的版本，扩展名是.xls；XSSFWorkbook:是操作Excel2007的版本，扩展名是.xlsx。对于不同版本的EXCEL文档要使用不同的工具类，如果使用错了，会提示如下错误信息：org.apache.poi.openxml4j.exceptions.InvalidOperationException，org.apache.poi.poifs.filesystem.OfficeXmlFileException\nHSSFWorkbook 的使用  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263  package com.knowledge.point; import org.apache.poi.hssf.usermodel.*; import org.apache.poi.ss.usermodel.Font; import java.io.*; import java.util.ArrayList; import java.util.HashMap; import java.util.List; import java.util.Map; /** * @author: latinos-bub * @date: 2019/11/12 17:32 * @description: 测试生成 excel * @className: com.knowledge.point.TestGenExcel */ public class TestGenExcel { public static void main(String[] args) throws Exception{ // 创建一个 excel 工作簿  HSSFWorkbook workbook = new HSSFWorkbook(); // 创建一个 excel 里面的 sheet 表格，并设置 sheet 名字  HSSFSheet sheet = workbook.createSheet(\"测试生成 excel 表格是否乱码\"); // -------------------------------设置 工作簿的 样式 start--------------------------//  HSSFCellStyle titleStyle = workbook.createCellStyle(); // 创建标题样式  titleStyle.setAlignment(HSSFCellStyle.ALIGN_CENTER); // 设置标题水平居中显示  titleStyle.setVerticalAlignment(HSSFCellStyle.VERTICAL_CENTER); // 设置标题垂直居中显示  HSSFFont titleFont = workbook.createFont(); // 创建标题字体  titleFont.setItalic(false); // 设置字体为斜体字  titleFont.setColor(Font.COLOR_RED); // 将字体设置为“红色”  titleFont.setFontHeightInPoints((short)16); // 将字体大小设置为18px  titleFont.setFontName(\"宋体\"); // 将“宋体”字体应用到当前单元格上  titleFont.setBoldweight(HSSFFont.BOLDWEIGHT_BOLD); //加粗  titleStyle.setFont(titleFont); // 将 字体应用到 标题样式上  HSSFCellStyle cellStyle = workbook.createCellStyle(); // 创建 cell 单元格样式  cellStyle.setAlignment(HSSFCellStyle.ALIGN_CENTER); // 设置 cell 单元格水平居中显示  cellStyle.setVerticalAlignment(HSSFCellStyle.VERTICAL_CENTER); // 设置 cell 单元格垂直居中显示  Font cellFont = workbook.createFont(); // 创建 单元格 字体  cellFont.setFontHeightInPoints((short)10); // 将字体大小设置为18px  cellFont.setFontName(\"宋体\"); // 字体应用到当前单元格上  cellStyle.setFont(cellFont); // 将 字体应用到 单元格样式上  // -------------------------------设置 工作簿的 样式 end--------------------------//  // 创建 首行(即标题 行)  HSSFRow headRow = sheet.createRow(0); // 创建 首行(即标题 行) 的 第一个单元格  HSSFCell headCell = headRow.createCell(0); // 设置 首行(即标题 行)的文字内容  headCell.setCellValue(\"更新时间\"); headCell.setCellStyle(titleStyle); // 设置 首行的 第一个单元格 样式  // 创建 首行(即标题 行) 的 第二个单元格  headCell = headRow.createCell(1); headCell.setCellValue(\"创建时间\"); headCell.setCellStyle(titleStyle); // 这里一定要每次实例化之后都要设置样式  headCell = headRow.createCell(2); headCell.setCellValue(\"删除状态\"); headCell.setCellStyle(titleStyle); // 这里一定要每次实例化之后都要设置样式  headCell = headRow.createCell(3); headCell.setCellValue(\"id\"); headCell.setCellStyle(titleStyle); // 这里一定要每次实例化之后都要设置样式  headCell = headRow.createCell(4); headCell.setCellValue(\"书名\"); headCell.setCellStyle(titleStyle); // 这里一定要每次实例化之后都要设置样式  // 获取 模拟的 List\u003cMap\u003cString, Object\u003e 数据  List\u003cMap\u003cString, Object\u003e\u003e list = getList(); for (int i = 0; i \u003c list.size(); i++){ // 外层for是每一行的设置  // 每一行(填充的内容行)时，我们都要新实例化一个 HSSRow 新行  HSSFRow contentRow = sheet.createRow(sheet.getLastRowNum() + 1); // 调用sheet的上次最后一行索引 + 1即可  for (int j = 0; j \u003c 5; j++){ // 内层 for 是 每行的 列数设置，因为我们的标题行有5列，所以这里设置5列  // 每一行，我们都要在该行(即contentRow) 实例化 5 个 cell 单元格  HSSFCell contentCell = contentRow.createCell(j); switch (j){ // 1，2，3，4，5个单元格分别写入自己正确的数据  case 0: // 每一行的第一列(即第一个cell)我们都写入 update_time 对应的数据，以下依次类推  contentCell.setCellValue(String.valueOf(list.get(i).get(\"update_time\"))); break; case 1: contentCell.setCellValue(String.valueOf(list.get(i).get(\"create_time\"))); break; case 2: contentCell.setCellValue(String.valueOf(list.get(i).get(\"delete_status\"))); break; case 3: contentCell.setCellValue(String.valueOf(list.get(i).get(\"id\"))); break; case 4: contentCell.setCellValue(String.valueOf(list.get(i).get(\"content\"))); break; } // 设置 内容 居中显示 样式  contentCell.setCellStyle(cellStyle); } } // 设置 列 的宽度  sheet.setColumnWidth(0, 900 * 10); sheet.setColumnWidth(1, 900 * 10); sheet.setColumnWidth(2, 900 * 10); sheet.setColumnWidth(3, 900 * 10); sheet.setColumnWidth(4, 900 * 10); File xlsFile = new File(\"测试生成Excel.xls\"); workbook.write(new FileOutputStream(xlsFile)); workbook.close(); // 补充：如果是 web 程序，需要页面打开一个对话框，保存文件则，需要额外添加以下代码即可  /*String fileName = \"excel表\"; fileName = new String(fileName.getBytes(), \"ISO-8859-1\"); HttpServletResponse response = this.getResponse().getHttpResponse(); response.setHeader(\"Content-disposition\", \"attachment; filename=\" + fileName + \".xls\"); response.setContentType(\"application/application/vnd.ms-excel;charset=utf-8\"); ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream(); // workbook 工作簿中写入数据 workbook.write(byteArrayOutputStream); byte[] content = byteArrayOutputStream.toByteArray(); InputStream inputStream = new ByteArrayInputStream(content); ServletOutputStream out = null; try { out = response.getOutputStream(); byte[] b = new byte[2048]; // 设置 缓冲区的读取字节大小 int i; while ((i = inputStream.read(b)) \u003e 0) { out.write(b, 0, i); } out.flush(); } catch (Exception e) { System.out.println(\"生成excel表格时出错: \" + e.getMessage()); } finally { if (inputStream != null) inputStream.close(); if (out != null) out.close(); }*/ } /** * @Author latinos-bub * @Description //TODO 这里我先准备一个从别的地方获取的 sql 结果集合，以备下面写入数据使用 * 这个 List 中我们就存放 12 个 Map 即可(模拟数据) * @Date 2019/11/12 21:17 * @Param [] * @return java.util.List\u003cjava.util.Map\u003cjava.lang.String,java.lang.Object\u003e\u003e **/ private static List\u003cMap\u003cString, Object\u003e\u003e getList(){ List\u003cMap\u003cString, Object\u003e\u003e list = new ArrayList\u003cMap\u003cString, Object\u003e\u003e(); Map\u003cString, Object\u003e map1 = new HashMap\u003cString, Object\u003e(); map1.put(\"update_time\", \"1569404166000\"); map1.put(\"create_time\", \"1569404122000\"); map1.put(\"delete_status\", \"1\"); map1.put(\"id\", \"2\"); map1.put(\"content\", \"如何削铁\"); list.add(map1); Map\u003cString, Object\u003e map2 = new HashMap\u003cString, Object\u003e(); map2.put(\"update_time\", \"1509357581000\"); map2.put(\"create_time\", \"1508893725000\"); map2.put(\"delete_status\", \"1\"); map2.put(\"id\", \"5\"); map2.put(\"content\", \"莎士比亚\"); list.add(map2); Map\u003cString, Object\u003e map3 = new HashMap\u003cString, Object\u003e(); map3.put(\"update_time\", \"1510970055000\"); map3.put(\"create_time\", \"1508986168000\"); map3.put(\"delete_status\", \"1\"); map3.put(\"id\", \"6\"); map3.put(\"content\", \"亚里士多德\"); list.add(map3); Map\u003cString, Object\u003e map4 = new HashMap\u003cString, Object\u003e(); map4.put(\"update_time\", \"1510118932000\"); map4.put(\"create_time\", \"1509001065000\"); map4.put(\"delete_status\", \"1\"); map4.put(\"id\", \"10\"); map4.put(\"content\", \"亚历山大\"); list.add(map4); Map\u003cString, Object\u003e map5 = new HashMap\u003cString, Object\u003e(); map5.put(\"update_time\", \"1509002622000\"); map5.put(\"create_time\", \"1509002622000\"); map5.put(\"delete_status\", \"0\"); map5.put(\"id\", \"11\"); map5.put(\"content\", \"李白\"); list.add(map5); Map\u003cString, Object\u003e map6 = new HashMap\u003cString, Object\u003e(); map6.put(\"update_time\", \"1569376168000\"); map6.put(\"create_time\", \"1569404290000\"); map6.put(\"delete_status\", \"1\"); map6.put(\"id\", \"12\"); map6.put(\"content\", \"无用是什么\"); list.add(map6); Map\u003cString, Object\u003e map7 = new HashMap\u003cString, Object\u003e(); map7.put(\"update_time\", \"1569376160000\"); map7.put(\"create_time\", \"1569404290000\"); map7.put(\"delete_status\", \"0\"); map7.put(\"id\", \"13\"); map7.put(\"content\", \"选择吃什么饭是一件很痛苦的事\"); list.add(map7); Map\u003cString, Object\u003e map8 = new HashMap\u003cString, Object\u003e(); map8.put(\"update_time\", \"1510983431000\"); map8.put(\"create_time\", \"1510983427000\"); map8.put(\"delete_status\", \"1\"); map8.put(\"id\", \"19\"); map8.put(\"content\", \"文章test2\"); list.add(map8); Map\u003cString, Object\u003e map9 = new HashMap\u003cString, Object\u003e(); map9.put(\"update_time\", \"1569376164000\"); map9.put(\"create_time\", \"1569404290000\"); map9.put(\"delete_status\", \"1\"); map9.put(\"id\", \"20\"); map9.put(\"content\", \"就像选择在哪里睡觉一样\"); list.add(map9); Map\u003cString, Object\u003e map10 = new HashMap\u003cString, Object\u003e(); map10.put(\"update_time\", \"1569376166000\"); map10.put(\"create_time\", \"1569404290000\"); map10.put(\"delete_status\", \"1\"); map10.put(\"id\", \"21\"); map10.put(\"content\", \"effective of java\"); list.add(map10); Map\u003cString, Object\u003e map11 = new HashMap\u003cString, Object\u003e(); map11.put(\"update_time\", \"1569376172000\"); map11.put(\"create_time\", \"1569404290000\"); map11.put(\"delete_status\", \"1\"); map11.put(\"id\", \"22\"); map11.put(\"content\", \"荒岛求生\"); list.add(map11); Map\u003cString, Object\u003e map12 = new HashMap\u003cString, Object\u003e(); map12.put(\"update_time\", \"1569376170000\"); map12.put(\"create_time\", \"1569404290000\"); map12.put(\"delete_status\", \"0\"); map12.put(\"id\", \"23\"); map12.put(\"content\", \"天使永远就在身边\"); list.add(map12); return list; } }    《行香子·归去来兮》 -- 北宋：辛弃疾   归去来兮，行乐休迟。命由天、富贵何时。 百年光景，七十者稀。奈一番愁，一番病，一番衰。 名利奔驰，宠辱惊疑。旧家时、都有些儿。 而今老矣，识破关机。算不如闲，不如醉，不如痴。\n ","description":"","tags":["Java"],"title":"Java中使用HSSFWorkbook生成excel","uri":"/java%E4%B8%AD%E4%BD%BF%E7%94%A8hssfworkbook%E7%94%9F%E6%88%90excel/"},{"categories":["编程"],"content":"java IO 操作分析 记录一下Java中传统IO是怎么操作的，这里还没有涉及到多线程的使用，后续我再补充吧。 直接看代码吧\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236  package jdk.util.sourceCode; import java.io.*; /** * 经常会遇到各种 IO 流操作，IO 流操作一般分为两类：字符流和字节流。 * 以 \"Reader\" 结尾都是字符流，操作的都是字符型的数据 * 以 \"Stream\" 结尾的都是字节流，操作的都是 byte 类型的数据 * 二者的区别： * 字节流没有缓冲区，是直接输出的；而字符流是先输出到缓冲区，然后在调用 close() 方法后再输出信息 * 处理对象不同，字节流能处理所有类型的数据，但是字符流只能处理字符类型的数据（只要是处理纯文本数据，就优先考虑使用字符流，除此之外都使用字节流） * java byte -\u003e short -\u003e int -\u003e long 1byte -\u003e 2byte -\u003e 4byte -\u003e 8byte * * * * InputStream 和 OutputStream 是各种输入输出字节流的基类，所有字节流都继承于这两个基类 * * * FileInputStream 和 FileOutputStream 这两个从字面意思很容易理解，是对文件的字节流操作，也是最常见的 IO 操作流 * * * 非流式文件类 -- File 类 * 从定义来看，File 类是 Object 的直接子类，同时它继承了 Comparable 接口可以进行数组的排序 * File 类的操作包括文件的创建，删除，重命名，得到文件/文件夹的路径，创建时间等 * File 类是对文件系统中文件以及文件夹进行封装的一个对象，可以通过对象的思想来操作文件和文件夹 * / /** * @author: util.you.com@gmail.com * @date: 2019/5/25 15:40 * @description: * @version: 1.0 * @className: TestIO */ public class TestIO { public static void main(String[] args){ // 1.调用 新建文件 // createFile(\"F:\\\\github\\\\util.you.com@gmail.com\\\\jdk\\\\src\\\\main\\\\java\\\\jdk\\\\util\\\\sourceCode\\\\\", \"测试io.txt\");  // 2.调用删除文件 // deleteFile(\"F:\\\\github\\\\util.you.com@gmail.com\\\\jdk\\\\src\\\\main\\\\java\\\\jdk\\\\util\\\\sourceCode\\\\\",\"测试io.txt\");  // 3.调用创建文件夹 // createFolder(\"F:\\\\github\\\\util.you.com@gmail.com\\\\jdk\\\\src\\\\main\\\\java\\\\jdk\\\\util\\\\sourceCode\\\\\", \"测试io文件夹\");  // 4.列出指定目录下面的所有文件，包括隐藏文件 // listFiles(\"F:\\\\github\\\\util.you.com@gmail.com\\\\jdk\\\\src\\\\main\\\\java\\\\jdk\\\\util\\\\sourceCode\\\\\");  // 5.判断指定的 文件夹是否是一个 目录(即是否是一个 文件夹) // isFolder(\"F:\\\\\\\\github\\\\\\\\util.you.com@gmail.com\\\\\\\\jdk\\\\\\\\src\\\\\\\\main\\\\\\\\java\\\\\\\\jdk\\\\\\\\util\\\\\\\\sourceCode\\\\\", \"测试io文件夹\");  // 6. 向指定的文件中(需要在文件名中给出路径和文件名,我这里是为了简便这样写了)通过 字节流 写入数据 (这里前提：认为该文件已经存在,不需要再创建) // writeFileByByte(\"F:\\\\github\\\\util.you.com@gmail.com\\\\jdk\\\\src\\\\main\\\\java\\\\jdk\\\\util\\\\sourceCode\\\\测试io.txt\");  // 7.从指定的文件中读取内容 // readFileByByte(\"F:\\\\github\\\\util.you.com@gmail.com\\\\jdk\\\\src\\\\main\\\\java\\\\jdk\\\\util\\\\sourceCode\\\\测试io.txt\");  // 8. 从 指定文件读取内容并写入到 目标文件  readWriteFile(\"F:\\\\game\\\\xx.mp4\", \"E:\\\\github-project\\\\jdk\\\\src\\\\main\\\\java\\\\jdk\\\\util\\\\sourceCode\\\\测试io.txt\"); } /** * 因为 io 流基本是与 File(文件/文件夹) 操作密不可分的，因此 io 的操作，只要涉及到文件，文件夹的都必须使用 File 类 * 在指定的路径下，新建一个 指定文件名的 文件 * @param path 文件路径 * @param fileName 文件名 */ public static void createFile(String path, String fileName){ // 因为是在 操作 文件，所以用到 File 对象【记住：所有与文件/文件夹操作相关的内容，都必须第一时间想到要用 File 对象】  File file = new File(path+fileName); // 实例化一个 file 操作对象  try { file.createNewFile(); // 调用 file 文件/文件夹 实例对象的 方法，来新建文件  System.out.println(\"目标文件已存在: \" + path + fileName); } catch (IOException e) { e.printStackTrace(); } } /** * 删除一个指定路径下的 文件 * @param path 该文件的路径 * @param fileName 该文件的文件名 */ public static void deleteFile(String path, String fileName){ File file = new File(path+fileName); if(file.exists()){ file.delete(); System.out.println(\"目标文件已删除\"); }else{ System.out.println(\"要删除的目标文件不存在\"); } } /** * 新建一个 文件夹 * @param path 路径 * @param folderName 文件夹名 */ public static void createFolder(String path, String folderName){ File file = new File(path+folderName); file.mkdir(); System.out.println(\"该文件夹已经存在于: \" + path + folderName); } /** * 列出指定目录下面的所有文件 * @param path 目录的路径名 */ public static void listFiles(String path){ File file = new File(path); if (file.isDirectory()){ File[] fileArray = file.listFiles(); for (int i = 0; i \u003c fileArray.length; i++){ System.out.println( \"该目录下的文件: \" + fileArray[i]); System.out.println( \"该目录下的文件或文件夹的名字: \" + fileArray[i].getName()); } }else{ System.out.println(path + \" 目录不存在\"); } } /** * 判断给定的 文件夹 是否是一个目录 * @param path */ public static void isFolder(String path, String folderName){ File file = new File(path + folderName); if (file.isDirectory()){ System.out.println(path + folderName + \" 是一个目录\"); }else{ System.out.println(path + folderName + \" 不是一个目录\"); } } /** * 通过 字节流 向 指定文件 写入内容 * @param fileName 文件名，这里为了简化，文件名中带上 路径 */ public static void writeFileByByte(String fileName){ File file = new File(fileName); OutputStream outputStream = null; // 从内存中 写入内容 到 文件中，这是输出流，因此要用 输出流  // FileOutputStream 的构造器大体上有两类：一类是 传入一个带有文件名和文件路径的字符串；另一类是 传入一个 File 文件/文件夹对象  try { outputStream = new FileOutputStream(file, true); // 给 file 文件对象 构造一个字节输出流  } catch (FileNotFoundException e) { e.printStackTrace(); } // 这里穿插一个小知识点，即我们 给一个 int 参数，但是我们要让 outputStream 以 byte[] 的形式写入,接下来就看 int 转 byte[] 吧  int a = 12345678; // 为什么这样呢？因为 一个 int 是 4个byte,所以一个 int 转成 byte[] 后，一定是里面包含4个byte元素的 byte[] 数组  byte[] b = new byte[]{ (byte) ((a \u003e\u003e 24) \u0026 0xFF), (byte) ((a \u003e\u003e 16) \u0026 0xFF), (byte) ((a \u003e\u003e 8) \u0026 0xFF), (byte) ((a ) \u0026 0xFF) }; try { outputStream.write(b); // 这里还有一个问题没解决：写入的时候，选择编码格式(稍后解决)  outputStream.close(); }catch (IOException e) { e.printStackTrace(); } } /** * 通过 字节流 从 指定文件 读取输出内容 * @param fileName 文件名，这里为了简化，文件名中带上 路径 */ public static void readFileByByte(String fileName){ File file = new File(fileName); InputStream inputStream = null; // 从 硬盘中 读取内容 到 内存中，这是 输入流，因此声明 输入流 对象  try { inputStream = new FileInputStream(file); // inputStream 读取内容有5个方法 read():默认读取一个byte,readBytes(byte b[], int off, int len)  // 这里我们采用 read(byte b[], int off, int len) 方法  byte[] byter = new byte[1024]; // 所以先实例化一个 byte[]  int len = inputStream.read(byter); inputStream.close(); // 最后我们输出一下读取到的内容  System.out.println(new String(byter, 0, len)); } catch (Exception e) { e.printStackTrace(); } } /** * @author: util.you.com@gmail.com * @param: [sourceFile, desFile] * @return: void * @date: 2019/5/25 18:04 * @version: 1.0 * @description: 最后来一个 从 指定文件中 读取内容 到 指定目标文件中 */ public static void readWriteFile(String sourceFile, String desFile){ File inputFile = new File(sourceFile); File outputFile = new File(desFile); InputStream inputStream = null; OutputStream outputStream = null; try { inputStream = new FileInputStream(inputFile); byte[] byter = new byte[1024]; inputStream.read(byter); outputStream = new FileOutputStream(outputFile, true); outputStream.write(byter); outputStream.close(); inputStream.close(); System.out.println(\"操作完成\"); }catch (Exception e){ System.out.println(e.getMessage()); } } }   ","description":"","tags":["Java"],"title":"Java中IO笔记","uri":"/java%E4%B8%ADio%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":" 静态代码的执行一定先于 main 方法，静态代码块和静态成员变量的执行顺序是由代码位置决定的，谁写前面就先执行谁   如果是非静态代码块和非静态成员变量，不执行  只有在创建 TestOrder 对象的时候，才会执行非静态代码块和非静态成员变量\n非静态代码块和非静态成员变量的执行顺序是由二者的顺序决定的。\n 如果同时存在非静态代码块和静态代码块，以及非静态成员变量和静态成员变量，执行顺序是怎样呢？  先执行静态的东西，并且只执行一次；再执行非静态的东西（只有在创建对象的情况下执行），创建多少个对象就执行多少次。\n 加入 父子类  1 2 3 4 5 6 7  public class Stub { public Stub(String str) { System.out.println(str + \"object created\"); } }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  public class Parent { static Stub parentStaticStub = new Stub(\"parent static object-\"); static{ System.out.println(\"parent static code execute\"); } { System.out.println(\"parent code execute\"); } Stub parentStub = new Stub(\"parent object-\"); Stub stub; public Parent(){ System.out.println(\"parent constructor execute\"); stub = new Stub(\"parent constructor create object-\"); } public void sayHello(){ System.out.println(\"hello from parent\"); } }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  public class Child extends Parent { static Stub childStaticStub = new Stub(\"child static object-\"); static { System.out.println(\"child static code execute\"); } { System.out.println(\"child code execute\"); } Stub childStub = new Stub(\"child object-\"); Stub stub; public Child(){ // 子类构造器中默认会有一个 super() 父类构造器  System.out.println(\"child constructor execute\"); stub = new Stub(\"child constructor create object-\"); } public void sayHello(){ System.out.println(\"hello from child\"); } }   1 2 3 4 5 6 7 8  public class Test { public static void main(String[] args) { Child child = new Child(); child.sayHello(); ((Parent)child).sayHello(); } }   执行结果：\n分析：\n①、首先会加载类 Parent，则 Parent 中的静态代码块和静态成员变量会优先执行。【首先会把相关的两个类加载到 JVM 内存中，然后才会创建调用对象等操作】\n②、加载 Child，则 Child 中的静态代码块和静态成员变量会优先执行。\n③、类加载完成后，就开始创建对象了，先创建 Parent 对象，创建对象之前，先创建对象的资源（指非静态代码块和非静态成员变量的执行）\n④、执行 Parent 构造器，完成对象的创建\n⑤、创建 Child 对象之前，先创建对象的资源\n⑥、执行 Child 构造器，完成对象的创建\n⑦、执行 sayHello 方法\n尽管进行了强制类型转换，但实际上对象还是内存中的 Child 对象，类型转换并不会涉及到对象的改变。\n","description":"","tags":["Java"],"title":"Java代码的执行顺序","uri":"/java%E4%BB%A3%E7%A0%81%E7%9A%84%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F/"},{"categories":["编程"],"content":"发现点 我们经常可以在github上看到国外大佬的commit信息中有很多可爱的表情，这是怎么做到的呢？ ok，可以这样使用哦：git commit -m '提交信息 :emoji:'，示例：git commit -m '增加新功能 :sparkles:'\n表情库 每个表情符都有其自己的表情代码，我们不可能自己去记吧。其实啊，网上早就有专门的这些表情站点免费提供我们使用哦， 有哪些呢？这里我提供几个站点供大家使用！！！\n gitmoji  emoji-cheat-sheet  full-emoji-list   ","description":"","tags":["笔记","Git"],"title":"Git Commit 提交信息时使用表情符","uri":"/git-commit-%E6%8F%90%E4%BA%A4%E4%BF%A1%E6%81%AF%E6%97%B6%E4%BD%BF%E7%94%A8%E8%A1%A8%E6%83%85%E7%AC%A6/"},{"categories":null,"content":"关于我\n\r\r喜欢的音乐\n   \r自我解剖\n我自认为我是属于90后中年龄偏大的一批人了，但是技术却很菜。我有时候的想法确实跟大部分人不同，说是不同吧，其实是几乎没人那么去想（从这一点也可以看出我很笨啦）；我虽然属于北方人，但是对于南北方的感受并没有多少的差异。\n公益视频\n\r","description":"","tags":null,"title":"关于我","uri":"/about/"}]
